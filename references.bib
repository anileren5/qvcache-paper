
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

@inproceedings{Covington:2016:DNN:YouTube,
  author    = {Covington, Paul and Adams, Jay and Sargin, Emre},
  title     = {Deep Neural Networks for {YouTube} Recommendations},
  booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
  series    = {RecSys '16},
  pages     = {191--198},
  year      = {2016},
  isbn      = {978-1-4503-4035-9},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2959100.2959190},
  url       = {https://doi.org/10.1145/2959100.2959190}
}

@inproceedings{Liu:2021:Q2S:Facebook,
  author    = {Liu, Yiqun and Rangadurai, Kaushik and He, Yunzhong and Malreddy, Siddarth and Gui, Xunlong and Liu, Xiaoyi and Borisyuk, Fedor},
  title     = {Que2Search: Fast and Accurate Query and Document Understanding for Search at Facebook},
  booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  series    = {KDD '21},
  pages     = {3376--3384},
  year      = {2021},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/3447548.3467127},
  url       = {https://doi.org/10.1145/3447548.3467127}
}

@inproceedings{Lewis:2020:RAG:NeurIPS,
  author    = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  title     = {{Retrieval-augmented generation for knowledge-intensive NLP tasks}},
  booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
  series    = {NeurIPS '20},
  pages     = {9459--9474},
  year      = {2020},
  volume    = {33},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  article   = {793}, % Sometimes used for the specific paper number
  url       = {https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf} % Using the direct PDF link for convenience
}

@misc{gao2024retrievalaugmentedgenerationlargelanguage,
      title={Retrieval-Augmented Generation for Large Language Models: A Survey}, 
      author={Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Meng Wang and Haofen Wang},
      year={2024},
      eprint={2312.10997},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.10997}, 
}

@inproceedings{task-embeddings-learning-query-embeddings-using-task-context,
author = {Mehrotra, Rishabh and Yilmaz, Emine},
title = {Task Embeddings: Learning Query Embeddings using Task Context},
year = {2017},
isbn = {9781450349185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132847.3133098},
doi = {10.1145/3132847.3133098},
abstract = {Continuous space word embedding have been shown to be highly effective in many information retrieval tasks. Embedding representation models make use of local information available in immediately surrounding words to project nearby context words closer in the embedding space. With rising multi-tasking nature of web search sessions, users often try to accomplish different tasks in a single search session. Consequently, the search context gets polluted with queries from different unrelated tasks which renders the context heterogeneous. In this work, we hypothesize that task information provides better context for IR systems to learn from. We propose a novel task context embedding architecture to learn representation of queries in low-dimensional space by leveraging their task context information from historical search logs using neural embedding models. In addition to qualitative analysis, we empirically demonstrate the benefit of leveraging task context to learn query representations.},
booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
pages = {2199–2202},
numpages = {4},
keywords = {neural embeddings, query representations, search tasks},
location = {Singapore, Singapore},
series = {CIKM '17}
}

@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@misc{mikolov2013efficientestimationwordrepresentations,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1301.3781}, 
}

@inproceedings{distributed-representations-of-sentences-and-documents,
author = {Le, Quoc and Mikolov, Tomas},
title = {Distributed representations of sentences and documents},
year = {2014},
publisher = {JMLR.org},
abstract = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {II–1188–II–1196},
location = {Beijing, China},
series = {ICML'14}
}

@article{graph-based-vector-search-evaluation,
author = {Azizi, Ilias and Echihabi, Karima and Palpanas, Themis},
title = {Graph-Based Vector Search: An Experimental Evaluation of the State-of-the-Art},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
url = {https://doi.org/10.1145/3709693},
doi = {10.1145/3709693},
abstract = {Vector data is prevalent across business and scientific applications, and its popularity is growing with the proliferation of learned embeddings. Vector data collections often reach billions of vectors with thousands of dimensions, thus, increasing the complexity of their analysis. Vector search is the backbone of many critical analytical tasks, and graph-based methods have become the best choice for analytical tasks that do not require guarantees on the quality of the answers. We briefly survey in-memory graph-based vector search, outline the chronology of the different methods and classify them according to five main design paradigms: seed selection, incremental insertion, neighborhood propagation, neighborhood diversification, and divide-and-conquer. We conduct an exhaustive experimental evaluation of twelve state-of-the-art methods on seven real data collections, with sizes up to 1 billion vectors. We share key insights about the strengths and limitations of these methods; e.g., the best approaches are typically based on incremental insertion and neighborhood diversification, and the choice of the base graph can hurt scalability. Finally, we discuss open research directions, such as the importance of devising more sophisticated data-adaptive seed selection and diversification strategies.},
journal = {Proc. ACM Manag. Data},
month = feb,
articleno = {43},
numpages = {31},
keywords = {approximate nearest neighbor, graph algorithms, knn graph analysis, neighborhood diversification, seed selection, vector similarity search}
}

@article{HNSWMalkovY16,
  author       = {Yury A. Malkov and
                  Dmitry A. Yashunin},
  title        = {Efficient and robust approximate nearest neighbor search using Hierarchical
                  Navigable Small World graphs},
  journal      = {CoRR},
  volume       = {abs/1603.09320},
  year         = {2016},
  url          = {http://arxiv.org/abs/1603.09320},
  eprinttype    = {arXiv},
  eprint       = {1603.09320},
  timestamp    = {Thu, 26 Aug 2021 08:49:44 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/MalkovY16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inbook{diskann,
author = {Subramanya, Suhas Jayaram and Devvrit and Kadekodi, Rohan and Krishaswamy, Ravishankar and Simhadri, Harsha Vardhan},
title = {DiskANN: fast accurate billion-point nearest neighbor search on a single node},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Current state-of-the-art approximate nearest neighbor search (ANNS) algorithms generate indices that must be stored in main memory for fast high-recall search. This makes them expensive and limits the size of the dataset. We present a new graph-based indexing and search system called DiskANN that can index, store, and search a billion point database on a single workstation with just 64GB RAM and an inexpensive solid-state drive (SSD). Contrary to current wisdom, we demonstrate that the SSD-based indices built by DiskANN can meet all three desiderata for large-scale ANNS: high-recall, low query latency and high density (points indexed per node). On the billion point SIFT1B bigann dataset, DiskANN serves > 5000 queries a second with < 3ms mean latency and 95\%+ 1-recall@1 on a 16 core machine, where state-of-the-art billion-point ANNS algorithms with similar memory footprint like FAISS [18] and IVFOADC+G+P [8] plateau at around 50\% 1-recall@1. Alternately, in the high recall regime, DiskANN can index and serve 5 - 10x more points per node compared to state-of-the-art graph-based methods such as HNSW [21] and NSG [13]. Finally, as part of our overall DiskANN system, we introduce Vamana, a new graph-based ANNS index that is more versatile than the existing graph indices even for in-memory indices.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {1233},
numpages = {11}
}

@article{product-quantization,
author = {Jegou, Herve and Douze, Matthijs and Schmid, Cordelia},
title = {Product Quantization for Nearest Neighbor Search},
year = {2011},
issue_date = {January 2011},
publisher = {IEEE Computer Society},
address = {USA},
volume = {33},
number = {1},
issn = {0162-8828},
url = {https://doi.org/10.1109/TPAMI.2010.57},
doi = {10.1109/TPAMI.2010.57},
abstract = {This paper introduces a product quantization-based approach for approximate nearest neighbor search. The idea is to decompose the space into a Cartesian product of low-dimensional subspaces and to quantize each subspace separately. A vector is represented by a short code composed of its subspace quantization indices. The euclidean distance between two vectors can be efficiently estimated from their codes. An asymmetric version increases precision, as it computes the approximate distance between a vector and a code. Experimental results show that our approach searches for nearest neighbors efficiently, in particular in combination with an inverted file system. Results for SIFT and GIST image descriptors show excellent search accuracy, outperforming three state-of-the-art approaches. The scalability of our approach is validated on a data set of two billion vectors.},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = jan,
pages = {117–128},
numpages = {12},
keywords = {High-dimensional indexing, High-dimensional indexing, image indexing, very large databases, approximate search., approximate search., image indexing, very large databases}
}

@inproceedings{locality-sensitive-hashing,
author = {Gionis, Aristides and Indyk, Piotr and Motwani, Rajeev},
title = {Similarity Search in High Dimensions via Hashing},
year = {1999},
isbn = {1558606157},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the 25th International Conference on Very Large Data Bases},
pages = {518–529},
numpages = {12},
series = {VLDB '99}
}

@inproceedings{kd-tree-nn,
author = {Ram, Parikshit and Sinha, Kaushik},
title = {Revisiting kd-tree for Nearest Neighbor Search},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330875},
doi = {10.1145/3292500.3330875},
abstract = {kdtree citefriedman1976algorithm has long been deemed unsuitable for exact nearest-neighbor search in high dimensional data. The theoretical guarantees and the empirical performance of kdtree do not show significant improvements over brute-force nearest-neighbor search in moderate to high dimensions. kdtree has been used relatively more successfully for approximate search citemuja2009flann but lack theoretical guarantees. In the article, we build upon randomized-partition trees citedasgupta2013randomized to propose kdtree based approximate search schemes with $O(d \l{}og d + \l{}og n)$ query time for data sets with n points in d dimensions and rigorous theoretical guarantees on the search accuracy. We empirically validate the search accuracy and the query time guarantees of our proposed schemes, demonstrating the significantly improved scaling for same level of accuracy.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {1378–1388},
numpages = {11},
keywords = {space-partitioning trees, similarity search, randomized algorithms, nearest-neighbor search},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@misc{ann-analyses,
      title={Approximate Nearest Neighbor Search on High Dimensional Data --- Experiments, Analyses, and Improvement (v1.0)}, 
      author={Wen Li and Ying Zhang and Yifang Sun and Wei Wang and Wenjie Zhang and Xuemin Lin},
      year={2016},
      eprint={1610.02455},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/1610.02455}, 
}

@inproceedings{spann,
author = {Chen, Qi and Zhao, Bing and Wang, Haidong and Li, Mingqin and Liu, Chuanjie and Li, Zengzhong and Yang, Mao and Wang, Jingdong},
title = {SPANN: highly-efficient billion-scale approximate nearest neighbor search},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The in-memory algorithms for approximate nearest neighbor search (ANNS) have achieved great success for fast high-recall search, but are extremely expensive when handling very large scale database. Thus, there is an increasing request for the hybrid ANNS solutions with small memory and inexpensive solid-state drive (SSD). In this paper, we present a simple but efficient memory-disk hybrid indexing and search system, named SPANN, that follows the inverted index methodology. It stores the centroid points of the posting lists in the memory and the large posting lists in the disk. We guarantee both disk-access efficiency (low latency) and high recall by effectively reducing the disk-access number and retrieving high-quality posting lists. In the index-building stage, we adopt a hierarchical balanced clustering algorithm to balance the length of posting lists and augment the posting list by adding the points in the closure of the corresponding clusters. In the search stage, we use a query-aware scheme to dynamically prune the access of unnecessary posting lists. Experiment results demonstrate that SPANN is 2\texttimes{} faster than the state-of-the-art ANNS solution DiskANN to reach the same recall quality 90\% with same memory cost in three billion-scale datasets. It can reach 90\% recall@1 and recall@10 in just around one millisecond with only about 10\% of original memory cost.},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {398},
numpages = {14},
series = {NIPS '21}
}

@article{elpis,
author = {Azizi, Ilias and Echihabi, Karima and Palpanas, Themis},
title = {ELPIS: Graph-Based Similarity Search for Scalable Data Science},
year = {2023},
issue_date = {February 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {6},
issn = {2150-8097},
url = {https://doi.org/10.14778/3583140.3583166},
doi = {10.14778/3583140.3583166},
abstract = {The recent popularity of learned embeddings has fueled the growth of massive collections of high-dimensional (high-d) vectors that model complex data. Finding similar vectors in these collections is at the core of many important and practical data science applications. The data series community has developed tree-based similarity search techniques that outperform state-of-the-art methods on large collections of both data series and generic high-d vectors, on all scenarios except for no-guarantees ng-approximate search, where graph-based approaches designed by the high-d vector community achieve the best performance. However, building graph-based indexes is extremely expensive both in time and space. In this paper, we bring these two worlds together, study the corresponding solutions and their performance behavior, and propose ELPIS, a new strong baseline that takes advantage of the best features of both to achieve a superior performance in terms of indexing and ng-approximate search in-memory. ELPIS builds the index 3x-8x faster than competitors, using 40\% less memory. It also achieves a high recall of 0.99, up to 2x faster than the state-of-the-art methods, and answers 1-NN queries up to one order of magnitude faster.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {1548–1559},
numpages = {12}
}

@misc{faiss,
      title={Billion-scale similarity search with GPUs}, 
      author={Jeff Johnson and Matthijs Douze and Hervé Jégou},
      year={2017},
      eprint={1702.08734},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1702.08734}, 
}

@article{nsg,
author = {Fu, Cong and Xiang, Chao and Wang, Changxu and Cai, Deng},
title = {Fast approximate nearest neighbor search with the navigating spreading-out graph},
year = {2019},
issue_date = {January 2019},
publisher = {VLDB Endowment},
volume = {12},
number = {5},
issn = {2150-8097},
url = {https://doi.org/10.14778/3303753.3303754},
doi = {10.14778/3303753.3303754},
abstract = {Approximate nearest neighbor search (ANNS) is a fundamental problem in databases and data mining. A scalable ANNS algorithm should be both memory-efficient and fast. Some early graph-based approaches have shown attractive theoretical guarantees on search time complexity, but they all suffer from the problem of high indexing time complexity. Recently, some graph-based methods have been proposed to reduce indexing complexity by approximating the traditional graphs; these methods have achieved revolutionary performance on million-scale datasets. Yet, they still can not scale to billion-node databases. In this paper, to further improve the search-efficiency and scalability of graph-based methods, we start by introducing four aspects: (1) ensuring the connectivity of the graph; (2) lowering the average out-degree of the graph for fast traversal; (3) shortening the search path; and (4) reducing the index size. Then, we propose a novel graph structure called Monotonic Relative Neighborhood Graph (MRNG) which guarantees very low search complexity (close to logarithmic time). To further lower the indexing complexity and make it practical for billion-node ANNS problems, we propose a novel graph structure named Navigating Spreading-out Graph (NSG) by approximating the MRNG. The NSG takes the four aspects into account simultaneously. Extensive experiments show that NSG outperforms all the existing algorithms significantly. In addition, NSG shows superior performance in the E-commercial scenario of Taobao (Alibaba Group) and has been integrated into their billion-scale search engine.},
journal = {Proc. VLDB Endow.},
month = jan,
pages = {461–474},
numpages = {14}
}

@inproceedings{milvus,
author = {Wang, Jianguo and Yi, Xiaomeng and Guo, Rentong and Jin, Hai and Xu, Peng and Li, Shengjun and Wang, Xiangyu and Guo, Xiangzhou and Li, Chengming and Xu, Xiaohai and Yu, Kun and Yuan, Yuxing and Zou, Yinghao and Long, Jiquan and Cai, Yudong and Li, Zhenxiang and Zhang, Zhifeng and Mo, Yihua and Gu, Jun and Jiang, Ruiyi and Wei, Yi and Xie, Charles},
title = {Milvus: A Purpose-Built Vector Data Management System},
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3457550},
doi = {10.1145/3448016.3457550},
abstract = {Recently, there has been a pressing need to manage high-dimensional vector data in data science and AI applications. This trend is fueled by the proliferation of unstructured data and machine learning (ML), where ML models usually transform unstructured data into feature vectors for data analytics, e.g., product recommendation. Existing systems and algorithms for managing vector data have two limitations: (1) They incur serious performance issue when handling large-scale and dynamic vector data; and (2) They provide limited functionalities that cannot meet the requirements of versatile applications.This paper presents Milvus, a purpose-built data management system to efficiently manage large-scale vector data. Milvus supports easy-to-use application interfaces (including SDKs and RESTful APIs); optimizes for the heterogeneous computing platform with modern CPUs and GPUs; enables advanced query processing beyond simple vector similarity search; handles dynamic data for fast updates while ensuring efficient query processing; and distributes data across multiple nodes to achieve scalability and availability. We first describe the design and implementation of Milvus. Then we demonstrate the real-world use cases supported by Milvus. In particular, we build a series of 10 applications (e.g., image/video search, chemical structure analysis, COVID-19 dataset search, personalized recommendation, biological multi-factor authentication, intelligent question answering) on top of Milvus. Finally, we experimentally evaluate Milvus with a wide range of systems including two open source systems (Vearch and Microsoft SPTAG) and three commercial systems. Experiments show that Milvus is up to two orders of magnitude faster than the competitors while providing more functionalities. Now Milvus is deployed by hundreds of organizations worldwide and it is also recognized as an incubation-stage project of the LF AI \& Data Foundation. Milvus is open-sourced at https://github.com/milvus-io/milvus.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {2614–2627},
numpages = {14},
keywords = {vector database, machine learning, high-dimensional similarity search, heterogeneous computing, data science},
location = {Virtual Event, China},
series = {SIGMOD '21}
}

@misc{scalablediskbasedapproximatenearest,
      title={Scalable Disk-Based Approximate Nearest Neighbor Search with Page-Aligned Graph}, 
      author={Dingyi Kang and Dongming Jiang and Hanshen Yang and Hang Liu and Bingzhe Li},
      year={2025},
      eprint={2509.25487},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2509.25487}, 
}

@misc{qdrant2025,
  author       = {{Qdrant}},
  title        = {Qdrant: High-performance, massive-scale vector database and vector search engine},
  year         = {2025},
  howpublished = {\url{https://github.com/qdrant/qdrant}},
  note         = {Accessed: 2025-10-05}
}

@misc{weaviate2025,
  author       = {{Weaviate}},
  title        = {Weaviate: Open-source vector database},
  year         = {2025},
  howpublished = {\url{https://github.com/weaviate/weaviate}},
  note         = {Accessed: 2025-10-05}
}

@misc{parlayann,
      title={ParlayANN: Scalable and Deterministic Parallel Graph-Based Approximate Nearest Neighbor Search Algorithms}, 
      author={Magdalen Dobson Manohar and Zheqi Shen and Guy E. Blelloch and Laxman Dhulipala and Yan Gu and Harsha Vardhan Simhadri and Yihan Sun},
      year={2024},
      eprint={2305.04359},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2305.04359}, 
}

@misc{bang,
      title={BANG: Billion-Scale Approximate Nearest Neighbor Search using a Single GPU}, 
      author={Karthik V. and Saim Khan and Somesh Singh and Harsha Vardhan Simhadri and Jyothi Vedurada},
      year={2025},
      eprint={2401.11324},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2401.11324}, 
}

@misc{scalablegraphindexingusinggpus,
      title={Scalable Graph Indexing using GPUs for Approximate Nearest Neighbor Search}, 
      author={Zhonggen Li and Xiangyu Ke and Yifan Zhu and Bocheng Yu and Baihua Zheng and Yunjun Gao},
      year={2025},
      eprint={2508.08744},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2508.08744}, 
}

@article{vector-search-delayed-fpga,
author = {Jiang, Wenqi and Hu, Hang and Hoefler, Torsten and Alonso, Gustavo},
title = {Fast Graph Vector Search via Hardware Acceleration and Delayed-Synchronization Traversal},
year = {2025},
issue_date = {July 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3749646.3749655},
doi = {10.14778/3749646.3749655},
abstract = {Vector search systems are indispensable in large language model (LLM) serving, search engines, and recommender systems, where minimizing online search latency is essential. Among various algorithms, graph-based vector search (GVS) is particularly popular due to its high search performance and quality. However, reducing GVS latency by intra-query parallelization remains challenging due to limitations imposed by both existing hardware architectures (CPUs and GPUs) and the inherent difficulty of parallelizing graph traversals. To efficiently serve low-latency GVS, we co-design hardware and algorithm by proposing Falcon and Delayed-Synchronization Traversal (DST). Falcon is a hardware GVS accelerator that implements efficient GVS operators, pipelines these operators, and reduces memory accesses by tracking search states with an on-chip Bloom filter. DST is an efficient graph traversal algorithm that simultaneously improves search performance and quality by relaxing traversal orders to maximize accelerator utilization. Evaluation across various graphs and datasets shows that Falcon, prototyped on FPGAs, together with DST, achieves up to 4.3X and 19.5X lower latency and up to 8.0X and 26.9X improvements in energy efficiency over CPU- and GPU-based GVS systems.},
journal = {Proc. VLDB Endow.},
month = sep,
pages = {3797–3811},
numpages = {15}
}

@inproceedings{memory-hierarchy,
  title={Memory Hierarchy in Cache-Based Systems},
  author={Ruud van der Pas},
  year={2002},
  url={https://api.semanticscholar.org/CorpusID:18765250}
}

@article{caching-search-query-results,
author = {Markatos, E.P},
title = {On caching search engine query results},
year = {2001},
issue_date = {February, 2001},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {24},
number = {2},
issn = {0140-3664},
url = {https://doi.org/10.1016/S0140-3664(00)00308-X},
doi = {10.1016/S0140-3664(00)00308-X},
abstract = {In this paper we explore the problem of Caching of Search Engine Query Results in order to reduce the computing and I/O requirements needed to support the functionality of a search engine of the World Wide Web. We study query traces from the EXCITE search engine and show that they have a significant amount of temporal locality that is, a significant percentage of the queries have been submitted more than once by the same or a different user. Using trace-driven simulation we demonstrate that medium-size caches can hold the results of most of the frequently submitted queries. Finally, we compare the effectiveness of static and dynamic caching and conclude that although dynamic caching can use large caches more effectively, static caching can perform better for (very) small caches.},
journal = {Comput. Commun.},
month = feb,
pages = {137–143},
numpages = {7},
keywords = {Caching, High-performance computers, Search engines}
}

@misc{garetto2021similaritycachingtheoryalgorithms,
      title={Similarity Caching: Theory and Algorithms}, 
      author={Michele Garetto and Emilio Leonardi and Giovanni Neglia},
      year={2021},
      eprint={1912.03888},
      archivePrefix={arXiv},
      primaryClass={cs.NI},
      url={https://arxiv.org/abs/1912.03888}, 
}

@article{dbmin,
  author = {Chou, H. T. and DeWitt, D. J.},
  title = {An Evaluation of Buffer Management Strategies for Relational Database Systems},
  journal = {Algorithmica},
  volume = {1},
  number = {4},
  pages = {311--336},
  year = {1986},
  doi = {10.1007/BF01840450},
  url = {https://doi.org/10.1007/BF01840450}
}

@inproceedings{data-caching-for-enterprise-scale,
author = {Tang, Chunxu and Fan, Bin and Zhao, Jing and Liang, Chen and Wang, Yi and Wang, Beinan and Qiu, Ziyue and Qiu, Lu and Ding, Bowen and Sun, Shouzhuo and Che, Saiguang and Mai, Jiaming and Chen, Shouwei and Zhu, Yu and Xie, Jianjian and Sun, Yutian (James) and Li, Yao and Zhang, Yangjun and Wang, Ke and Chen, Mingmin},
title = {Data caching for enterprise-grade petabyte-scale OLAP},
year = {2024},
isbn = {978-1-939133-41-0},
publisher = {USENIX Association},
address = {USA},
abstract = {With the exponential growth of data and evolving use cases, petabyte-scale OLAP data platforms are increasingly adopting a model that decouples compute from storage. This shift, evident in organizations like Uber and Meta, introduces operational challenges including massive, read-heavy I/O traffic with potential throttling, as well as skewed and fragmented data access patterns. Addressing these challenges, this paper introduces the Alluxio local (edge) cache, a highly effective architectural optimization tailored for such environments. This embeddable cache, optimized for petabyte-scale data analytics, leverages local SSD resources to alleviate network I/O and API call pressures, significantly improving data transfer efficiency. Integrated with OLAP systems like Presto and storage services like HDFS, the Alluxio local cache has demonstrated its effectiveness in handling large-scale, enterprise-grade workloads over three years of deployment at Uber and Meta. We share insights and operational experiences in implementing these optimizations, providing valuable perspectives on managing modern, massive-scale OLAP workloads.},
booktitle = {Proceedings of the 2024 USENIX Conference on Usenix Annual Technical Conference},
articleno = {55},
numpages = {15},
location = {Santa Clara, CA, USA},
series = {USENIX ATC'24}
}

@inproceedings{caching-intermediate-results,
author = {Yang, Mengdong and Wu, Gang},
title = {Caching intermediate result of SPARQL queries},
year = {2011},
isbn = {9781450306379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963192.1963273},
doi = {10.1145/1963192.1963273},
abstract = {The complexity and growing scale of RDF data has made data management back end the performance bottleneck of Semantic Web applications. Caching is one of the ways that could solve this problem. However, few existing research projects focus on caching in RDF data processing. We present an adaptive caching scheme that caches intermediate result of basic graph pattern SPARQL queries. Benchmark test results are provided to illustrate the effectiveness of our caching scheme.},
booktitle = {Proceedings of the 20th International Conference Companion on World Wide Web},
pages = {159–160},
numpages = {2},
keywords = {SPARQL, cache, intermediate result},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{memcached,
  author = {Rajesh Nishtala and Hans Fugal and Steven Grimm and Marc Kwiatkowski and Herman Lee and Harry C. Li and Ryan McElroy and Mike Paleczny and Daniel Peek and Paul Saab and David Stafford and Tony Tung and Venkateshwaran Venkataramani},
  title = {Scaling Memcache at Facebook},
  booktitle = {Proceedings of the 10th USENIX Symposium on Networked Systems Design and Implementation (NSDI '13)},
  year = {2013},
  pages = {385--398},
  publisher = {USENIX Association},
  url = {https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf}
}

@misc{redis2025,
  author = {Redis},
  title = {Redis: In-memory data structure store},
  year = {2025},
  url = {https://github.com/redis/redis},
  note = {Accessed: 2025-10-05}
}

@inproceedings{vdbms-survey-sigmod,
author = {Pan, James Jie and Wang, Jianguo and Li, Guoliang},
title = {Vector Database Management Techniques and Systems},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3654691},
doi = {10.1145/3626246.3654691},
abstract = {Feature vectors are now mission-critical for many applications, including retrieval-based large language models (LLMs). Traditional database management systems are not equipped to deal with the unique characteristics of feature vectors, such as the vague notion of semantic similarity, large size of vectors, expensive similarity comparisons, lack of indexable structure, and difficulty of answering "hybrid" queries that combine structured attributes with feature vectors. A number of vector database management systems (VDBMSs) have been developed to address these challenges, combining novel techniques for query processing, storage and indexing, and query optimization and execution and culminating in a spectrum of performance and accuracy characteristics and capabilities. In this tutorial, we review the existing vector database management techniques and systems. For query processing, we review similarity score design and selection, vector query types, and vector query interfaces. For storage and indexing, we review various indexes and discuss compression as well as disk-resident indexes. For query optimization and execution, we review hybrid query processing, hardware acceleration, and distibuted search. We then review existing systems, search engines and libraries, and benchmarks. Finally, we present research challenges and open problems.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {597–604},
numpages = {8},
keywords = {dense retrieval, k-NN, vector database, vector similarity search},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

@misc{vdbms-survey-extensive,
      title={A Comprehensive Survey on Vector Database: Storage and Retrieval Technique, Challenge}, 
      author={Le Ma and Ran Zhang and Yikun Han and Shirui Yu and Zaitian Wang and Zhiyuan Ning and Jinghan Zhang and Ping Xu and Pengjiang Li and Wei Ju and Chong Chen and Dongjie Wang and Kunpeng Liu and Pengyang Wang and Pengfei Wang and Yanjie Fu and Chunjiang Liu and Yuanchun Zhou and Chang-Tien Lu},
      year={2025},
      eprint={2310.11703},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2310.11703}, 
}

@INPROCEEDINGS{tiered-cache-hnsw,
  author={Masuda, Rei and Iwamoto, Kazuma and Ando, Kazuaki and Kamei, Hitoshi},
  booktitle={2025 1st International Conference on Consumer Technology (ICCT-Pacific)}, 
  title={Tiered Cache-HNSW: Using Hierarchical Caching System in HNSW}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  keywords={Costs;Generative AI;Databases;Retrieval augmented generation;Memory management;Nearest neighbor methods;Information retrieval;Vectors;System analysis and design;RAG;Hierarchical Caching;Categorization},
  doi={10.1109/ICCT-Pacific63901.2025.11012786}}

@inproceedings{similarity-caching,
author = {Chierichetti, Flavio and Kumar, Ravi and Vassilvitskii, Sergei},
title = {Similarity caching},
year = {2009},
isbn = {9781605585536},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1559795.1559815},
doi = {10.1145/1559795.1559815},
abstract = {We introduce the similarity caching problem, a variant of classical caching in which an algorithm can return an element from the cache that is similar, but not necessarily identical, to the query element. We are motivated by buffer management questions in approximate nearest-neighbor applications, especially in the context of caching targeted advertisements on the web. Formally, we assume the queries lie in a metric space, with distance function d(.,.). A query p is considered a cache hit if there is a point q in the cache that is sufficiently close to p, i.e., for a threshold radius r, we have d(p,q) ≤ r. The goal is then to minimize the number of cache misses, vis-\`{a}-vis the optimal algorithm. As with classical caching, we use the competitive ratio to measure the performance of different algorithms.While similarity caching is a strict generalization of classical caching, we show that unless the algorithm is allowed extra power (either in the size of the cache or the threshold r) over the optimal offline algorithm, the problem is intractable. We then proceed to quantify the hardness as a function of the complexity of the underlying metric space. We show that the problem becomes easier as we proceed from general metric spaces to those of bounded doubling dimension, and to Euclidean metrics. Finally, we investigate several extensions of the problem: dependence of the threshold r on the query and a smoother trade-off between the cache-miss cost and the query-query similarity.},
booktitle = {Proceedings of the Twenty-Eighth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
pages = {127–136},
numpages = {10},
keywords = {buffer management, caching, competitive analysis, nearest-neighbor},
location = {Providence, Rhode Island, USA},
series = {PODS '09}
}

@article{similarity-caching-theory-algorithms,
author = {Neglia, Giovanni and Garetto, Michele and Leonardi, Emilio},
title = {Similarity Caching: Theory and Algorithms},
year = {2021},
issue_date = {April 2022},
publisher = {IEEE Press},
volume = {30},
number = {2},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2021.3126368},
doi = {10.1109/TNET.2021.3126368},
abstract = {This paper focuses on similarity caching systems, in which a user request for an object <inline-formula> <tex-math notation="LaTeX">$o$ </tex-math></inline-formula> that is not in the cache can be (partially) satisfied by a similar stored object <inline-formula> <tex-math notation="LaTeX">$o'$ </tex-math></inline-formula>, at the cost of a loss of user utility. Similarity caching systems can be effectively employed in several application areas, like multimedia retrieval, recommender systems, genome study, and machine learning training/serving. However, despite their relevance, the behavior of such systems is far from being well understood. In this paper, we provide a first comprehensive analysis of similarity caching in the offline, adversarial, and stochastic settings. We show that similarity caching raises significant new challenges, for which we propose the first dynamic policies with some optimality guarantees. We evaluate the performance of our schemes under both synthetic and real request traces.},
journal = {IEEE/ACM Trans. Netw.},
month = dec,
pages = {475–486},
numpages = {12}
}

@inproceedings{gptcache,
    title = "{GPTC}ache: An Open-Source Semantic Cache for {LLM} Applications Enabling Faster Answers and Cost Savings",
    author = "Bang, Fu",
    editor = "Tan, Liling  and
      Milajevs, Dmitrijs  and
      Chauhan, Geeticka  and
      Gwinnup, Jeremy  and
      Rippeth, Elijah",
    booktitle = "Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023)",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.nlposs-1.24/",
    doi = "10.18653/v1/2023.nlposs-1.24",
    pages = "212--218",
    abstract = "The rise of ChatGPT1 has led to the development of artificial intelligence (AI) applications, particularly those that rely on large language models (LLMs). However, recalling LLM APIs can be expensive, and the response speed may slow down during LLMs' peak times, causing frustration among developers. Potential solutions to this problem include using better LLM models or investing in more computing resources. However, these options may increase product development costs and decrease development speed. GPTCache2 is an open-source semantic cache that stores LLM responses to address this issue. When integrating an AI application with GPTCache, user queries are first sent to GPTCache for a response before being sent to LLMs like ChatGPT. If GPTCache has the answer to a query, it quickly returns the answer to the user without having to query the LLM. This approach saves costs on API recalls and makes response times much faster. For instance, integrating GPTCache with the GPT service offered by OpenAI can increase response speed 2-10 times when the cache is hit. Moreover, network fluctuations will not affect GPTCache{'}s response time, making it highly stable. This paper presents GPTCache and its architecture, how it functions and performs, and the use cases for which it is most advantageous."
}

@misc{vcache,
      title={vCache: Verified Semantic Prompt Caching}, 
      author={Luis Gaspar Schroeder and Aditya Desai and Alejandro Cuadron and Kyle Chu and Shu Liu and Mark Zhao and Stephan Krusche and Alfons Kemper and Ion Stoica and Matei Zaharia and Joseph E. Gonzalez},
      year={2025},
      eprint={2502.03771},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.03771}, 
}

@article{freshdiskann,
  title={FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search},
  author={Aditi Singh and Suhas Jayaram Subramanya and Ravishankar Krishnaswamy and Harsha Vardhan Simhadri},
  journal={ArXiv},
  year={2021},
  volume={abs/2105.09613},
  url={https://api.semanticscholar.org/CorpusID:234790132}
}

@article{10.1145/170036.170081,
author = {O'Neil, Elizabeth J. and O'Neil, Patrick E. and Weikum, Gerhard},
title = {The LRU-K page replacement algorithm for database disk buffering},
year = {1993},
issue_date = {June 1, 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/170036.170081},
doi = {10.1145/170036.170081},
abstract = {This paper introduces a new approach to database disk buffering, called the LRU-K method. The basic idea of LRU-K is to keep track of the times of the last K references to popular database pages, using this information to statistically estimate the interarrival times of references on a page by page basis. Although the LRU-K approach performs optimal statistical inference under relatively standard assumptions, it is fairly simple and incurs little bookkeeping overhead. As we demonstrate with simulation experiments, the LRU-K algorithm surpasses conventional buffering algorithms in discriminating between frequently and infrequently referenced pages. In fact, LRU-K can approach the behavior of buffering algorithms in which page sets with known access frequencies are manually assigned to different buffer pools of specifically tuned sizes. Unlike such customized buffering algorithms however, the LRU-K method is self-tuning, and does not rely on external hints about workload characteristics. Furthermore, the LRU-K algorithm adapts in real time to changing patterns of access.},
journal = {SIGMOD Rec.},
month = jun,
pages = {297–306},
numpages = {10}
}

@inproceedings{lru-k-page-replacement,
author = {O'Neil, Elizabeth J. and O'Neil, Patrick E. and Weikum, Gerhard},
title = {The LRU-K page replacement algorithm for database disk buffering},
year = {1993},
isbn = {0897915925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/170035.170081},
doi = {10.1145/170035.170081},
abstract = {This paper introduces a new approach to database disk buffering, called the LRU-K method. The basic idea of LRU-K is to keep track of the times of the last K references to popular database pages, using this information to statistically estimate the interarrival times of references on a page by page basis. Although the LRU-K approach performs optimal statistical inference under relatively standard assumptions, it is fairly simple and incurs little bookkeeping overhead. As we demonstrate with simulation experiments, the LRU-K algorithm surpasses conventional buffering algorithms in discriminating between frequently and infrequently referenced pages. In fact, LRU-K can approach the behavior of buffering algorithms in which page sets with known access frequencies are manually assigned to different buffer pools of specifically tuned sizes. Unlike such customized buffering algorithms however, the LRU-K method is self-tuning, and does not rely on external hints about workload characteristics. Furthermore, the LRU-K algorithm adapts in real time to changing patterns of access.},
booktitle = {Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data},
pages = {297–306},
numpages = {10},
location = {Washington, D.C., USA},
series = {SIGMOD '93}
}

@article{working-set,
author = {Denning, Peter J.},
title = {The working set model for program behavior},
year = {1968},
issue_date = {May 1968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {5},
issn = {0001-0782},
url = {https://doi.org/10.1145/363095.363141},
doi = {10.1145/363095.363141},
journal = {Commun. ACM},
month = may,
pages = {323–333},
numpages = {11},
keywords = {storage allocation, scheduling, resource allocation, program models, program behavior, operating systems, multiprogramming, multiprocessing, general operating system concepts}
}
@article{turbocharging-vector-databases-ssds,
author = {Shim, Joobo and Oh, Jaewon and Roh, Hongchan and Do, Jaeyoung and Lee, Sang-Won},
title = {Turbocharging Vector Databases Using Modern SSDs},
year = {2025},
issue_date = {July 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3749646.3749724},
doi = {10.14778/3749646.3749724},
abstract = {Efficient and scalable vector search is critical for modern AI applications, particularly in retrieval-augmented generation (RAG) and large-scale semantic search. However, disk-based vector databases often suffer from significant I/O bottlenecks due to suboptimal cache hit ratios and inefficient use of modern SSD architectures. In this work, we introduce a suite of optimizations to enhance the performance of disk-resident Approximate Nearest Neighbor (ANN) indices, specifically focusing on hierarchical graph-based indexing such as HNSW. Our approach leverages three key strategies: (1) Parallel I/O leveraging io_uring to exploit SSD concurrency and reduce retrieval latency, (2) Spatially-aware insertion reordering to improve cache efficiency by dynamically adjusting insert execution order based on locality, and (3) Locality-preserving colocation to restructure index layouts and minimize costly random disk accesses.We implement these techniques within pgvector, a PostgreSQL extension for vector search, and conduct extensive evaluations using real-world datasets. Our optimizations yield up to 11.1\texttimes{} improvement in query throughput, a 3.23\texttimes{} increase in cache hit ratio, and a 98.4\% reduction in index build time. Moreover, our findings underscore the importance of SSD-aware indexing strategies for scalable vector retrieval. By integrating hardware-aware I/O optimizations with intelligent data placement techniques, this work paves the way for more efficient, high-performance disk-based vector search engines that could fully leverage modern SSD's high parallelism.},
journal = {Proc. VLDB Endow.},
month = sep,
pages = {4710–4722},
numpages = {13}
}

@misc{semanticequivalenceecommercequeries,
      title={Semantic Equivalence of e-Commerce Queries}, 
      author={Aritra Mandal and Daniel Tunkelang and Zhe Wu},
      year={2023},
      eprint={2308.03869},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2308.03869}, 
}

@inproceedings{semantic-similarity-temporal-correlation,
author = {Chien, Steve and Immorlica, Nicole},
title = {Semantic similarity between search engine queries using temporal correlation},
year = {2005},
isbn = {1595930469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1060745.1060752},
doi = {10.1145/1060745.1060752},
abstract = {We investigate the idea of finding semantically related search engine queries based on their temporal correlation; in other words, we infer that two queries are related if their popularities behave similarly over time. To this end, we first define a new measure of the temporal correlation of two queries based on the correlation coefficient of their frequency functions. We then conduct extensive experiments using our measure on two massive query streams from the MSN search engine, revealing that this technique can discover a wide range of semantically similar queries. Finally, we develop a method of efficiently finding the highest correlated queries for a given input query using far less space and time than the naive approach, making real-time implementation possible.},
booktitle = {Proceedings of the 14th International Conference on World Wide Web},
pages = {2–11},
numpages = {10},
keywords = {semantic similarity among queries, search engines, query stream analysis},
location = {Chiba, Japan},
series = {WWW '05}
}

@misc{incrementalivfindexmaintenance,
      title={Incremental IVF Index Maintenance for Streaming Vector Search}, 
      author={Jason Mohoney and Anil Pacaci and Shihabur Rahman Chowdhury and Umar Farooq Minhas and Jeffery Pound and Cedric Renggli and Nima Reyhani and Ihab F. Ilyas and Theodoros Rekatsinas and Shivaram Venkataraman},
      year={2024},
      eprint={2411.00970},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2411.00970}, 
}

@misc{ZillizServerless2025,
  author       = {Zilliz Inc.},
  title        = {Zilliz Cloud Serverless – High‑Performance Vector Database Made Serverless},
  howpublished = {\url{https://zilliz.com/serverless}},
  note         = {Accessed: 2025‑10‑31},
  year         = {2025}
}

@inproceedings{amazon-shop-the-look,
author = {Du, Ming and Ramisa, Arnau and K C, Amit Kumar and Chanda, Sampath and Wang, Mengjiao and Rajesh, Neelakandan and Li, Shasha and Hu, Yingchuan and Zhou, Tao and Lakshminarayana, Nagashri and Tran, Son and Gray, Doug},
title = {Amazon Shop the Look: A Visual Search System for Fashion and Home},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539071},
doi = {10.1145/3534678.3539071},
abstract = {In this paper, we introduce Shop the Look, a web-scale fashion and home product visual search system deployed at Amazon. Building such a system poses great challenges to both science and engineering practices. We leverage large-scale image data from the Amazon product catalog and adopt effective strategies to reduce the human effort required to annotate data. By employing state-of-the-art computer vision techniques, we train detection, recognition, and feature extraction models to bridge the domain gap between in-the-wild query images and product images which are taken under controlled settings. Our system is designed to achieve a balance between result accuracy and efficiency. The run-time service is optimized to provide retrieval results to users with low-latency. The scalable offline index-building pipeline adapts to the dynamic Amazon catalog that contains billions of products. We present both quantitative and qualitative evaluation results to demonstrate the performance of our system. We believe that the fast-growing Shop the Look service is shaping the way that customers shop on Amazon.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2822–2830},
numpages = {9},
keywords = {deep learning, image retrieval, online shopping, visual search},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{visrel,
author = {Borisyuk, Fedor and Malreddy, Siddarth and Mei, Jun and Liu, Yiqun and Liu, Xiaoyi and Maheshwari, Piyush and Bell, Anthony and Rangadurai, Kaushik},
title = {VisRel: Media Search at Scale},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467081},
doi = {10.1145/3447548.3467081},
abstract = {In this paper, we present VisRel, a deployed large-scale media search system that leverages text understanding, media understanding, and multimodal technologies to deliver a modern multimedia search experience. We share our insight on developing image and video understanding models for content retrieval, training efficient and effective media-to-query relevance models, and refining online and offline metrics to measure the success of one of the largest media search databases in the industry. We summarize our learnings gathered from hundreds of A/B test experiments and describe the most effective technical approaches. The techniques presented in this work have contributed 34\% (abs.) improvement to media-to-query relevance and 10\% improvement to user engagement. We believe that this work can provide practical solutions and insights for engineers who are interested in applying media understanding technologies to empower multimedia search systems that operate at Facebook scale.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
pages = {2584–2592},
numpages = {9},
keywords = {video search, multi-modal learning, media search, image search, image classification},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{adamoptimizer,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={CoRR},
  year={2014},
  volume={abs/1412.6980},
  url={https://api.semanticscholar.org/CorpusID:6628106}
}

@misc{principalcomponentanalysis,
      title={A Tutorial on Principal Component Analysis}, 
      author={Jonathon Shlens},
      year={2014},
      eprint={1404.1100},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1404.1100}, 
}

@inproceedings{workingset,
author = {Denning, Peter J.},
title = {The working set model for program behavior},
year = {1967},
isbn = {9781450373708},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800001.811670},
doi = {10.1145/800001.811670},
abstract = {Probably the most basic reason behind the absence of a general treatment of resource allocation in modern computer systems is an adequate model for program behavior. In this paper a new model is developed, the “working set model”, which enables us to decide which information is in use by a running program and which is not. Such knowledge is vital for dynamic management of paged memories. The working set of pages associated with a process, defined to be the collection of its most recently used pages, is a useful allocation concept. A proposal for an easy-to-implement allocation policy is set forth; this policy is unique, inasmuch as it blends into one decision function the heretofore independent activities of process-scheduling and memory-management.},
booktitle = {Proceedings of the First ACM Symposium on Operating System Principles},
pages = {15.1–15.12},
series = {SOSP '67}
}

@misc{sift,
      title={Searching in one billion vectors: re-rank with source coding}, 
      author={Hervé Jégou and Romain Tavenard and Matthijs Douze and Laurent Amsaleg},
      year={2011},
      eprint={1102.3828},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/1102.3828}, 
}

@INPROCEEDINGS{deep,
  author={Yandex, Artem Babenko and Lempitsky, Victor},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Efficient Indexing of Billion-Scale Datasets of Deep Descriptors}, 
  year={2016},
  volume={},
  number={},
  pages={2055-2063},
  keywords={Indexing;Computer vision;Correlation;Vector quantization},
  doi={10.1109/CVPR.2016.226}}

@article{gist,
  author    = {Aude Oliva and Antonio Torralba},
  title     = {Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope},
  journal   = {International Journal of Computer Vision},
  volume    = {42},
  number    = {3},
  pages     = {145--175},
  year      = {2001},
  month     = {May},
  doi       = {10.1023/A:1011139631724},
  url       = {https://doi.org/10.1023/A:1011139631724},
  issn      = {1573-1405},
}

@inproceedings{pennington-etal-2014-glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    editor = "Moschitti, Alessandro  and
      Pang, Bo  and
      Daelemans, Walter",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162/",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543"
}

@misc{yandex-both-text2iamge-deep,
  author       = {Dmitry Baranchuk and Artem Babenko},
  title        = {Benchmarks for Billion-Scale Similarity Search},
  howpublished = {\url{https://research.yandex.com/blog/benchmarks-for-billion-scale-similarity-search}},
  month        = {April},
  year         = {2021},
  note         = {Accessed: 2025-12-07}
}

@misc{SPACEV1B_SPTAG,
  author       = {{Microsoft}},
  title        = {SPACEV1B: A billion-scale vector dataset for text descriptors},
  howpublished = {\url{https://github.com/microsoft/SPTAG/tree/main/datasets/SPACEV1B}},
  year         = {2023},
  note         = {Accessed: 2025-12-07}
}

@misc{yu2025topologyawarelocalizedupdatestrategy,
      title={A Topology-Aware Localized Update Strategy for Graph-Based ANN Index}, 
      author={Song Yu and Shengyuan Lin and Shufeng Gong and Yongqing Xie and Ruicheng Liu and Yijie Zhou and Ji Sun and Yanfeng Zhang and Guoliang Li and Ge Yu},
      year={2025},
      eprint={2503.00402},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2503.00402}, 
}

@article{douze2024faiss,
  title   = {The Faiss library},
  author  = {Matthijs Douze and Alexandr Guzhva and Chengqi Deng and Jeff Johnson and Gergely Szilvasy and Pierre-Emmanuel Mazaré and Maria Lomeli and Lucas Hosseini and Hervé Jégou},
  year    = {2024},
  eprint  = {2401.08281},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG}
}

@misc{pgvector,
  title  = {pgvector: Open‑source vector similarity search for PostgreSQL},
  howpublished = {GitHub repository},  
  note   = {accessed 2025-12-07},
  url    = {https://github.com/pgvector/pgvector}
}

@misc{pinecone,
  title  = {Pinecone Vector Database},
  howpublished = {Pinecone product website},  
  note   = {accessed 2025-12-07},
  url    = {https://www.pinecone.io}
}

@article{belady1966study,
  title        = {A study of replacement algorithms for a virtual-storage computer},
  author       = {Belady, L. A.},
  journal      = {IBM Systems Journal},
  volume       = {5},
  number       = {2},
  pages        = {78--101},
  year         = {1966},
  doi          = {10.1147/SJ.52.0078}
}

@misc{gray1998fiveminuteruleyearslater,
      title={The Five-Minute Rule Ten Years Later, and Other Computer Storage Rules of Thumb}, 
      author={Jim Gray and Goetz Graefe},
      year={1998},
      eprint={cs/9809005},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/cs/9809005}, 
}

@INPROCEEDINGS{7816668,
  author={Shi, Zhan and Lu, Kai and Wang, Xiao-Ping and Zhang, Wen-Zhe},
  booktitle={2016 International Conference on Information System and Artificial Intelligence (ISAI)}, 
  title={Dynamic Page Size Adjustment in Operating System}, 
  year={2016},
  volume={},
  number={},
  pages={24-28},
  keywords={Monitoring;Memory management;Linux;Operating systems;Instruction sets;Benchmark testing;Runtime;virtual memory;huge page;memory access monitoring;translation lookaside buffer miss;incremental checkpoint},
  doi={10.1109/ISAI.2016.0015}}


@inproceedings{Zimmerer_2025, series={SIGMOD/PODS ’25},
   title={Pruning in Snowflake: Working Smarter, Not Harder},
   url={http://dx.doi.org/10.1145/3722212.3724447},
   DOI={10.1145/3722212.3724447},
   booktitle={Companion of the 2025 International Conference on Management of Data},
   publisher={ACM},
   author={Zimmerer, Andreas and Dam, Damien and Kossmann, Jan and Waack, Juliane and Oukid, Ismail and Kipf, Andreas},
   year={2025},
   month=jun, pages={757–770},
   collection={SIGMOD/PODS ’25} }

@inproceedings{10.1145/2882903.2903741,
author = {Dageville, Benoit and Cruanes, Thierry and Zukowski, Marcin and Antonov, Vadim and Avanes, Artin and Bock, Jon and Claybaugh, Jonathan and Engovatov, Daniel and Hentschel, Martin and Huang, Jiansheng and Lee, Allison W. and Motivala, Ashish and Munir, Abdul Q. and Pelley, Steven and Povinec, Peter and Rahn, Greg and Triantafyllis, Spyridon and Unterbrunner, Philipp},
title = {The Snowflake Elastic Data Warehouse},
year = {2016},
isbn = {9781450335317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2882903.2903741},
doi = {10.1145/2882903.2903741},
abstract = {We live in the golden age of distributed computing. Public cloud platforms now offer virtually unlimited compute and storage resources on demand. At the same time, the Software-as-a-Service (SaaS) model brings enterprise-class systems to users who previously could not afford such systems due to their cost and complexity. Alas, traditional data warehousing systems are struggling to fit into this new environment. For one thing, they have been designed for fixed resources and are thus unable to leverage the cloud's elasticity. For another thing, their dependence on complex ETL pipelines and physical tuning is at odds with the flexibility and freshness requirements of the cloud's new types of semi-structured data and rapidly evolving workloads. We decided a fundamental redesign was in order. Our mission was to build an enterprise-ready data warehousing solution for the cloud. The result is the Snowflake Elastic Data Warehouse, or "Snowflake" for short. Snowflake is a multi-tenant, transactional, secure, highly scalable and elastic system with full SQL support and built-in extensions for semi-structured and schema-less data. The system is offered as a pay-as-you-go service in the Amazon cloud. Users upload their data to the cloud and can immediately manage and query it using familiar tools and interfaces. Implementation began in late 2012 and Snowflake has been generally available since June 2015. Today, Snowflake is used in production by a growing number of small and large organizations alike. The system runs several million queries per day over multiple petabytes of data.In this paper, we describe the design of Snowflake and its novel multi-cluster, shared-data architecture. The paper highlights some of the key features of Snowflake: extreme elasticity and availability, semi-structured and schema-less data, time travel, and end-to-end security. It concludes with lessons learned and an outlook on ongoing work.},
booktitle = {Proceedings of the 2016 International Conference on Management of Data},
pages = {215–226},
numpages = {12},
keywords = {data warehousing, database as a service, multi-cluster shared data architecture},
location = {San Francisco, California, USA},
series = {SIGMOD '16}
}

@misc{OpenSearch,
  title        = {OpenSearch: Open Source Search and Analytics Suite},
  howpublished = {\url{https://opensearch.org/}},
  note         = {Accessed: 2025-12-14},
  year         = {2025},
  organization = {OpenSearch Software Foundation},
  url          = {https://opensearch.org/},
  description  = {OpenSearch is a community-driven, Apache 2.0-licensed open source search and analytics suite for ingesting, searching, visualizing, and analyzing data.},
}


@article{10.14778/3685800.3685806-gaussdb,
author = {Li, Guoliang and Tian, Wengang and Zhang, Jinyu and Grosman, Ronen and Liu, Zongchao and Li, Sihao},
title = {GaussDB: A Cloud-Native Multi-Primary Database with Compute-Memory-Storage Disaggregation},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685806},
doi = {10.14778/3685800.3685806},
abstract = {Cloud-native databases have been widely deployed due to high elasticity, high availability and low cost. However, most existing cloud-native databases do not support multiple writers and thus have limitations on write throughput and scalability. To alleviate this limitation, there is a need for multi-primary databases which provide high write throughput and high scalability.In this paper, we present a cloud-native multi-primary database, GaussDB, which adopts a three layer (compute-memory-storage) disaggregation framework, where the compute layer is in charge of transaction processing, the memory layer is responsible for global buffer management and global lock management, and the storage layer is used for page and log persistence. To provide multi-primary capabilities, GaussDB logically partitions the pages to different compute nodes and then assigns the ownership of each page to a compute node. For each transaction posed to a compute node, if the compute node owns all relevant pages of this query, the compute node can process the query locally; otherwise, GaussDB transfers the ownership of relevant pages to this node. To capture data affinity and reduce page transmission costs, GaussDB designs a novel page placement and query routing method. To improve recovery performance, GaussDB employs a two-tier (memory-storage) checkpoint recovery method which uses memory checkpoints combined with on-demand page recovery to significantly improve recovery performance. We have implemented and deployed GaussDB internally at Huawei and with customers, and the results show that GaussDB achieves higher throughput, lower latency, and faster recovery than state-of-the-art baselines.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {3786–3798},
numpages = {13}
}

@inproceedings{Jiang_2025, series={KDD ’25},
   title={A Survey on Retrieval And Structuring Augmented Generation with Large Language Models},
   url={http://dx.doi.org/10.1145/3711896.3736557},
   DOI={10.1145/3711896.3736557},
   booktitle={Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
   publisher={ACM},
   author={Jiang, Pengcheng and Ouyang, Siru and Jiao, Yizhu and Zhong, Ming and Tian, Runchu and Han, Jiawei},
   year={2025},
   month=aug, pages={6032–6042},
   collection={KDD ’25} }

@inproceedings{10.1145/3035918.3064009,
author = {Li, Hui and Chan, Tsz Nam and Yiu, Man Lung and Mamoulis, Nikos},
title = {FEXIPRO: Fast and Exact Inner Product Retrieval in Recommender Systems},
year = {2017},
isbn = {9781450341974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3035918.3064009},
doi = {10.1145/3035918.3064009},
abstract = {Recommender systems have many successful applications in e-commerce and social media, including Amazon, Netflix, and Yelp. Matrix Factorization (MF) is one of the most popular recommendation approaches; the original user-product rating matrix R with millions of rows and columns is decomposed into a user matrix Q and an item matrix P, such that the product QT P approximates R. Each column q (p) of Q (P) holds the latent factors of the corresponding user (item), and qT p is a prediction of the rating to item p by user q. Recommender systems based on MF suggest to a user in q the items with the top-k scores in qT P. For this problem, we propose a Fast and EXact Inner PROduct retrieval (FEXIPRO) framework, based on sequential scan, which includes three elements. First, FEXIPRO applies an SVD transformation to P, after which the first several dimensions capture a large percentage of the inner products. This enables us to prune item vectors by only computing their partial inner products with q. Second, we construct an integer approximation version of P, which can be used to compute fast upper bounds for the inner products that can prune item vectors. Finally, we apply a lossless transformation to P, such that the resulting matrix has only positive values, allowing for the inner products to be monotonically increasing with dimensionality. Experiments on real data demonstrate that our framework outperforms alternative approaches typically by an order of magnitude.},
booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},
pages = {835–850},
numpages = {16},
keywords = {similarity search, recommender systems, inner product},
location = {Chicago, Illinois, USA},
series = {SIGMOD '17}
}

@misc{shen2024learningretrievejobmatching,
      title={Learning to Retrieve for Job Matching}, 
      author={Jianqiang Shen and Yuchin Juan and Shaobo Zhang and Ping Liu and Wen Pu and Sriram Vasudevan and Qingquan Song and Fedor Borisyuk and Kay Qianqi Shen and Haichao Wei and Yunxiang Ren and Yeou S. Chiou and Sicong Kuang and Yuan Yin and Ben Zheng and Muchen Wu and Shaghayegh Gharghabi and Xiaoqing Wang and Huichao Xue and Qi Guo and Daniel Hewlett and Luke Simon and Liangjie Hong and Wenjing Zhang},
      year={2024},
      eprint={2402.13435},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2402.13435}, 
}

@article{veluru2025evolution,
  title   = {The Evolution of Search Engines: From Keyword Matching to AI-Powered Understanding},
  author  = {Veluru, Suhasnadh Reddy and Marella, Viswa Chaitanya and Erukude, Sai Teja},
  journal = {SSRN Electronic Journal},
  year    = {2025},
  month   = {June},
  doi     = {10.2139/ssrn.5403467},
  url     = {https://ssrn.com/abstract=5403467}
}

@article{10.14778/3750601.3750700,
author = {Chronis, Yannis and Caminal, Helena and Papakonstantinou, Yannis and \"{O}zcan, Fatma and Ailamaki, Anastasia},
title = {Filtered Vector Search: State-of-the-Art and Research Opportunities},
year = {2025},
issue_date = {August 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3750601.3750700},
doi = {10.14778/3750601.3750700},
abstract = {This tutorial provides a comprehensive overview of filtered vector search (fvs). Fvs queries combine vector search with relational operators. The tutorial explores the challenges of integrating vector search into database engines and emphasizes the need for new optimization techniques. It explains the three primary filtered search methods for fvs queries over generic tree-based and graph-based indices and examines the factors influencing the selection of the most efficient method. A key objective is to highlight the importance of achieving stable recall, ideally in a declarative manner, ensuring consistent recall across queries. The tutorial then discusses recent filter-optimized vector indices and concludes by identifying open research challenges in the field of fvs, aiming to inspire further research and development.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {5488–5492},
numpages = {5}
}

@article{Chen_2025,
   title={DiskJoin: Large-scale Vector Similarity Join with SSD},
   volume={3},
   ISSN={2836-6573},
   url={http://dx.doi.org/10.1145/3769780},
   DOI={10.1145/3769780},
   number={6},
   journal={Proceedings of the ACM on Management of Data},
   publisher={Association for Computing Machinery (ACM)},
   author={Chen, Yanqi and Yan, Xiao and Meliou, Alexandra and Lo, Eric},
   year={2025},
   month=dec, pages={1–27} }

@ARTICLE{9383170,
  author={Fu, Cong and Wang, Changxu and Cai, Deng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={High Dimensional Similarity Search With Satellite System Graph: Efficiency, Scalability, and Unindexed Query Compatibility}, 
  year={2022},
  volume={44},
  number={8},
  pages={4139-4150},
  keywords={Indexing;Complexity theory;Nearest neighbor methods;Satellites;Quantization (signal);Databases;Time complexity;Nearest neighbors;similarity search;high dimension;large-scale database},
  doi={10.1109/TPAMI.2021.3067706}}

@article{10.14778/3204028.3204034,
author = {Arora, Akhil and Sinha, Sakshi and Kumar, Piyush and Bhattacharya, Arnab},
title = {HD-index: pushing the scalability-accuracy boundary for approximate kNN search in high-dimensional spaces},
year = {2018},
issue_date = {April 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {8},
issn = {2150-8097},
url = {https://doi.org/10.14778/3204028.3204034},
doi = {10.14778/3204028.3204034},
abstract = {Nearest neighbor searching of large databases in high-dimensional spaces is inherently difficult due to the curse of dimensionality. A flavor of approximation is, therefore, necessary to practically solve the problem of nearest neighbor search. In this paper, we propose a novel yet simple indexing scheme, HD-Index, to solve the problem of approximate k-nearest neighbor queries in massive high-dimensional databases. HD-Index consists of a set of novel hierarchical structures called RDB-trees built on Hilbert keys of database objects. The leaves of the RDB-trees store distances of database objects to reference objects, thereby allowing efficient pruning using distance filters. In addition to triangular inequality, we also use Ptolemaic inequality to produce better lower bounds. Experiments on massive (up to billion scale) high-dimensional (up to 1000+) datasets show that HD-Index is effective, efficient, and scalable.},
journal = {Proc. VLDB Endow.},
month = apr,
pages = {906–919},
numpages = {14}
}

@misc{jafari2021surveylocalitysensitivehashing,
      title={A Survey on Locality Sensitive Hashing Algorithms and their Applications}, 
      author={Omid Jafari and Preeti Maurya and Parth Nagarkar and Khandker Mushfiqul Islam and Chidambaram Crushev},
      year={2021},
      eprint={2102.08942},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2102.08942}, 
}

@inproceedings{Lempitsky2015TheIM,
  title={The Inverted Multi-Index Artem Babenko and},
  author={Victor S. Lempitsky},
  year={2015},
  url={https://api.semanticscholar.org/CorpusID:202717754}
}

@misc{mohoney2025quakeadaptiveindexingvector,
      title={Quake: Adaptive Indexing for Vector Search}, 
      author={Jason Mohoney and Devesh Sarda and Mengze Tang and Shihabur Rahman Chowdhury and Anil Pacaci and Ihab F. Ilyas and Theodoros Rekatsinas and Shivaram Venkataraman},
      year={2025},
      eprint={2506.03437},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2506.03437}, 
}

@misc{xu2025inplaceupdatesgraphindex,
      title={In-Place Updates of a Graph Index for Streaming Approximate Nearest Neighbor Search}, 
      author={Haike Xu and Magdalen Dobson Manohar and Philip A. Bernstein and Badrish Chandramouli and Richard Wen and Harsha Vardhan Simhadri},
      year={2025},
      eprint={2502.13826},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2502.13826}, 
}

@misc{jeong2025callcontextawarelowlatencyretrieval,
      title={CALL: Context-Aware Low-Latency Retrieval in Disk-Based Vector Databases}, 
      author={Yeonwoo Jeong and Hyunji Cho and Kyuri Park and Youngjae Kim and Sungyong Park},
      year={2025},
      eprint={2509.18670},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2509.18670}, 
}

@article{10.14778/3685800.3685805,
author = {Chen, Cheng and Jin, Chenzhe and Zhang, Yunan and Podolsky, Sasha and Wu, Chun and Wang, Szu-Po and Hanson, Eric and Sun, Zhou and Walzer, Robert and Wang, Jianguo},
title = {SingleStore-V: An Integrated Vector Database System in SingleStore},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685805},
doi = {10.14778/3685800.3685805},
abstract = {Vector databases have recently gained significant attention due to the emergence of large language models that produce vector embeddings for text. Existing vector databases can be broadly categorized into two types: specialized and generalized. Specialized vector databases are explicitly designed and optimized for managing vector data, while generalized ones support vector data management within a general purpose database. While specialized vector databases are interesting, there is a substantial customer base interested in generalized vector databases for various reasons, e.g., a reluctance to move data out of relational databases to reduce data silos and costs, the desire to use SQL, and the need for more sophisticated query processing of vector and non-vector data. However, generalized vector databases face two main challenges: performance and interoperability of vector search with SQL, such as combining vector search with filters, joins, or even fulltext search.In this paper, we present SingleStore-V, a full-fledged generalized vector database integrated into SingleStore, a modern distributed relational database optimized for both OLAP and OLTP workloads. SingleStore-V achieves high performance and interoperability via a suite of optimizations. Experiments on standard vector benchmarks show that SingleStore-V performs comparably to Milvus, a highly-optimized specialized vector database, and significantly outperforms pgvector, a popular generalized vector database in PostgreSQL. We believe this paper will shed light on integrating vector search into relational databases in general, as many design concepts and optimizations apply to other databases.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {3772–3785},
numpages = {14}
}

@article{10.14778/3750601.3750679,
author = {Yan, Jianxin and Ni, Wangze and Chen, Lei and Lin, Xuemin and Cheng, Peng and Qin, Zhan and Ren, Kui},
title = {ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models},
year = {2025},
issue_date = {August 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3750601.3750679},
doi = {10.14778/3750601.3750679},
abstract = {Semantic caching significantly reduces computational costs and improves efficiency by storing and reusing large language model (LLM) responses. However, existing systems rely primarily on matching individual queries, lacking awareness of multi-turn dialogue contexts, which leads to incorrect cache hits when similar queries appear in different conversational settings. This demonstration introduces ContextCache, a context-aware semantic caching system for multi-turn dialogues. ContextCache employs a two-stage retrieval architecture that first executes vector-based retrieval on the current query to identify potential matches and then integrates current and historical dialogue representations through self-attention mechanisms for precise contextual matching. Evaluation of real-world conversations shows that ContextCache improves precision and recall compared to existing methods. Additionally, cached responses exhibit approximately 10 times lower latency than direct LLM invocation, enabling significant computational cost reductions for LLM conversational applications.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {5391–5394},
numpages = {4}
}

@article{10.1145/3578519,
author = {Frieder, Ophir and Mele, Ida and Muntean, Cristina Ioana and Nardini, Franco Maria and Perego, Raffaele and Tonellotto, Nicola},
title = {Caching Historical Embeddings in Conversational Search},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1559-1131},
url = {https://doi.org/10.1145/3578519},
doi = {10.1145/3578519},
abstract = {Rapid response, namely, low latency, is fundamental in search applications; it is particularly so in interactive search sessions, such as those encountered in conversational settings. An observation with a potential to reduce latency asserts that conversational queries exhibit a temporal locality in the lists of documents retrieved. Motivated by this observation, we propose and evaluate a client-side document embedding cache, improving the responsiveness of conversational search systems. By leveraging state-of-the-art dense retrieval models to abstract document and query semantics, we cache the embeddings of documents retrieved for a topic introduced in the conversation, as they are likely relevant to successive queries. Our document embedding cache implements an efficient metric index, answering nearest-neighbor similarity queries by estimating the approximate result sets returned. We demonstrate the efficiency achieved using our cache via reproducible experiments based on Text Retrieval Conference Conversational Assistant Track datasets, achieving a hit rate of up to 75\% without degrading answer quality. Our achieved high cache hit rates significantly improve the responsiveness of conversational systems while likewise reducing the number of queries managed on the search back-end.},
journal = {ACM Trans. Web},
month = oct,
articleno = {42},
numpages = {19},
keywords = {Conversational search, similarity search, caching, dense retrieval}
}

@article{10.14778/3685800.3685905,
author = {Zhao, Xinyang and Zhou, Xuanhe and Li, Guoliang},
title = {Chat2Data: An Interactive Data Analysis System with RAG, Vector Databases and LLMs},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685905},
doi = {10.14778/3685800.3685905},
abstract = {Traditional data analysis methods require users to write programming codes or issue SQL queries to analyze the data, which are inconvenient for ordinary users. Large language models (LLMs) can alleviate these limitations by enabling users to interact with the data with natural language (NL), e.g., result retrieval and summarization for unstructured data and transforming the NL text to SQL queries or codes for structured data. However, existing LLMs have three limitations: hallucination (due to lacking domain knowledge for vertical domains), high cost for LLM reasoning, and low accuracy for complicated tasks. To address these problems, we propose a prototype, Chat2Data, to interactively analyze the data with natural language. Chat2Data adopts a three-layer method, where the first layer uses Retrieval-Augmented Generation (RAG) to embed domain knowledge in order to address the hallucination problem, the second layer utilizes vector databases to reduce the number of interactions with LLMs so as to improve the performance, and the third layer designs a pipeline agent to decompose a complex task to multiple subtasks and use multiple round reasoning to generate the results in order to improve the accuracy of LLMs. We demonstrate Chat2Data with two real scenarios, unstructured data retrieval and summarization, and natural language-based structured data analysis. The online demo is available at http://vdemo.dbmind.cn.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4481–4484},
numpages = {4}
}

@inproceedings{10.1145/3721146.3721941,
author = {Bergman, Shai Aviram and Ji, Zhang and Kermarrec, Anne-Marie and Petrescu, Diana and Pires, Rafael and Randl, Mathis and de Vos, Martijn},
title = {Leveraging Approximate Caching for Faster Retrieval-Augmented Generation},
year = {2025},
isbn = {9798400715389},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721146.3721941},
doi = {10.1145/3721146.3721941},
abstract = {Retrieval-augmented generation (RAG) enhances the reliability of large language model (LLM) answers by integrating external knowledge. However, RAG increases the end-to-end inference time since looking for relevant documents from large vector databases is computationally expensive. To address this, we introduce Proximity, an approximate key-value cache that optimizes the RAG workflow by leveraging similarities in user queries. Instead of treating each query independently, Proximity reuses previously retrieved documents when similar queries appear, reducing reliance on expensive vector database lookups. We evaluate Proximity on the MMLU and MedRAG benchmarks, demonstrating that it significantly improves retrieval efficiency while maintaining response accuracy. Proximity reduces retrieval latency by up to 59\% while maintaining accuracy and lowers the computational burden on the vector database. We also experiment with different similarity thresholds and quantify the trade-off between speed and recall. Our work shows that approximate caching is a viable and effective strategy for optimizing RAG-based systems.},
booktitle = {Proceedings of the 5th Workshop on Machine Learning and Systems},
pages = {66–73},
numpages = {8},
keywords = {retrieval-augmented generation, large language models, approximate caching, neural information retrieval, vector databases, query optimization, latency reduction, machine learning systems},
location = {World Trade Center, Rotterdam, Netherlands},
series = {EuroMLSys '25}
}


@inproceedings {298625SmartANN,
author = {Bing Tian and Haikun Liu and Zhuohui Duan and Xiaofei Liao and Hai Jin and Yu Zhang},
title = {Scalable Billion-point Approximate Nearest Neighbor Search Using {SmartSSDs}},
booktitle = {2024 USENIX Annual Technical Conference (USENIX ATC 24)},
year = {2024},
isbn = {978-1-939133-41-0},
address = {Santa Clara, CA},
pages = {1135--1150},
url = {https://www.usenix.org/conference/atc24/presentation/tian},
publisher = {USENIX Association},
month = jul
}

@article{10.14778/2735461.2735465inmemoryperformanceforbigdata,
author = {Graefe, Goetz and Volos, Haris and Kimura, Hideaki and Kuno, Harumi and Tucek, Joseph and Lillibridge, Mark and Veitch, Alistair},
title = {In-memory performance for big data},
year = {2014},
issue_date = {September 2014},
publisher = {VLDB Endowment},
volume = {8},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/2735461.2735465},
doi = {10.14778/2735461.2735465},
abstract = {When a working set fits into memory, the overhead imposed by the buffer pool renders traditional databases non-competitive with in-memory designs that sacrifice the benefits of a buffer pool. However, despite the large memory available with modern hardware, data skew, shifting workloads, and complex mixed workloads make it difficult to guarantee that a working set will fit in memory. Hence, some recent work has focused on enabling in-memory databases to protect performance when the working data set almost fits in memory. Contrary to those prior efforts, we enable buffer pool designs to match in-memory performance while supporting the "big data" workloads that continue to require secondary storage, thus providing the best of both worlds. We introduce here a novel buffer pool design that adapts pointer swizzling for references between system objects (as opposed to application objects), and uses it to practically eliminate buffer pool overheads for memoryresident data. Our implementation and experimental evaluation demonstrate that we achieve graceful performance degradation when the working set grows to exceed the buffer pool size, and graceful improvement when the working set shrinks towards and below the memory and buffer pool sizes.},
journal = {Proc. VLDB Endow.},
month = sep,
pages = {37–48},
numpages = {12}
}


@misc{jaiswal2022ooddiskannefficientscalablegraph,
      title={OOD-DiskANN: Efficient and Scalable Graph ANNS for Out-of-Distribution Queries}, 
      author={Shikhar Jaiswal and Ravishankar Krishnaswamy and Ankit Garg and Harsha Vardhan Simhadri and Sheshansh Agrawal},
      year={2022},
      eprint={2211.12850},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.12850}, 
}

@article{10.14778/3750601.3750635cosmosdb,
author = {Upreti, Nitish and Simhadri, Harsha Vardhan and Sundar, Hari Sudan and Sundaram, Krishnan and Boshra, Samer and Perumalswamy, Balachandar and Atri, Shivam and Chisholm, Martin and Singh, Revti Raman and Yang, Greg and Hass, Tamara and Dudhey, Nitesh and Pattipaka, Subramanyam and Hildebrand, Mark and Manohar, Magdalen and Moffitt, Jack and Xu, Haiyang and Datha, Naren and Gupta, Suryansh and Krishnaswamy, Ravishankar and Gupta, Prashant and Sahu, Abhishek and Varada, Hemeswari and Barthwal, Sudhanshu and Mor, Ritika and Codella, James and Cooper, Shaun and Pilch, Kevin and Moreno, Simon and Kataria, Aayush and Kulkarni, Santosh and Deshpande, Neil and Sagare, Amar and Billa, Dinesh and Fu, Zishan and Vishal, Vipul},
title = {Cost-Effective, Low Latency Vector Search with Azure Cosmos DB},
year = {2025},
issue_date = {August 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3750601.3750635},
doi = {10.14778/3750601.3750635},
abstract = {Vector indexing enables semantic search over diverse corpora and has become an important interface to databases for both users and AI agents. Efficient vector search requires deep optimizations in database systems. This has motivated a new class of specialized vector databases that optimize for vector search quality and cost. Instead, we argue that a scalable, high-performance, and cost-efficient vector search system can be built inside a cloud-native operational database like Azure Cosmos DB while leveraging the benefits of a distributed database such as high availability, durability, and scale. We do this by deeply integrating DiskANN, a state-of-the-art vector indexing library, inside Azure Cosmos DB NoSQL. This system uses a single vector index per partition stored in existing index trees, and kept in sync with underlying data. It supports < 20ms query latency over an index spanning 10 million vectors, has stable recall over updates, and offers approximately 43\texttimes{} and 12\texttimes{} lower query cost compared to Pinecone and Zilliz serverless enterprise products. It also scales out to billions of vectors via automatic partitioning. This convergent design presents a point in favor of integrating vector indices into operational databases in the context of recent debates on specialized vector databases, and offers a template for vector indexing in other databases.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {5166–5183},
numpages = {18}
}

@article{10.14778/3712221.3712224,
author = {Lan, Hai and Huang, Shixun and Bao, Zhifeng and Borovica-Gajic, Renata},
title = {Cardinality Estimation for Similarity Search on High-Dimensional Data Objects: The Impact of Reference Objects},
year = {2024},
issue_date = {November 2024},
publisher = {VLDB Endowment},
volume = {18},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3712221.3712224},
doi = {10.14778/3712221.3712224},
abstract = {In this paper, we study the problem of cardinality estimation for similarity search on high-dimensional data (CE4HD). We aim to perform CE4HD with high data robustness (i.e., robust to different datasets), query robustness (i.e., robust to large cardinality variance and scale) and efficiency. We propose to leverage the cardinality estimation of selected objects (called reference objects) in the database to achieve the above. Specifically, we propose two techniques that adopt different strategies to select and leverage reference objects, as well as strategies to support efficient computation in dynamic databases. Extensive experiments on datasets from diverse domains show that our methods achieve up to ~10x speed-up and up to ~136x smaller mean Q-error compared to existing studies.},
journal = {Proc. VLDB Endow.},
month = nov,
pages = {544–556},
numpages = {13}
}