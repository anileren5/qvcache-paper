\section{Background}
In this section, we provide the preliminaries on vector search and the similarity caching problems, and we briefly review the FreshVamana index~\cite{freshdiskann}, which serves as the foundation for QVCache.

\textbf{Nearest Neighbor Search.} The objective of the \textit{k-nearest neighbor (k-NN)} problem, also referred to as vector search, can be formally defined as follows: Given a set of vectors $P$ in a $d$-dimensional space, i.e., $\forall p \in P, \; p \in \mathbb{R}^d$, and a query vector $q \in \mathbb{R}^d$, the goal is to identify a set $X \subseteq P$ of $k$ vectors closest to $q$ according to a distance function $d$. That is, $|X| = k  \land \forall p \in P \setminus X, \; d(q, x_i) \le d(q, p), \; x_i \in X.$ The most straightforward solution is \textit{exhaustive search}, which compares the query vector $q$ against all vectors in $P$, resulting in a time complexity of $O(|P|
 \cdot d)$. To reduce this computational cost, vector search research has largely focused on \textit{Approximate Nearest Neighbor (ANN) search}, which aims to minimize both the number of comparisons~\cite{diskann,HNSWMalkovY16,elpis,nsg,product-quantization,faiss,spann} and the cost of each comparison~\cite{product-quantization} with a trade-off of recall drop.

\textbf{Metrics.} To evaluate the accuracy of an ANN search method with respect to the ground-truth obtained via exhaustive search, the metric \textit{k-recall@k} is commonly used. It is computed as 
$
\frac{|X \cap G|}{k},
$ 
where $X$ denotes the set of neighbors returned by the ANN method, $G$ represents the ground-truth neighbors obtained from exhaustive search, and $k$ is the number of neighbors of interest for the query. For performance evaluation, \textit{latency} and \textit{throughput} (queries per second, QPS) are the two standard measures.


\textbf{Similarity Caching.}  
Vector caching builds upon the formal concept of the \textit{similarity caching} problem, where a user request for an object $O$ that is not in the cache may instead be served by a similar object $O'$ from the cache, at the cost of some degradation in user experience~\cite{similarity-caching-theory-algorithms}. The goal of similarity caching is to maximize the cache hit ratio while minimizing this degradation. A query $q$ requesting object $O$ results in a cache hit if there exists a cached object $O'$ retrieved by another query $p$ such that $d(q, p) \le r$, where $d$ is the distance (similarity) metric and $r$ is a similarity threshold~\cite{similarity-caching}. Choosing an appropriate value for $r$ is challenging: if $r=0$, the problem reduces to exact caching with nearly zero hit rate, while a large $r$ leads to poor user experience due to dissimilar results. Chierichetti et al.~\cite{similarity-caching} further show that the problem becomes even harder when $r$ is query-dependent, for which no competitive algorithm exists. Vector caching is exactly such a case, where the object requested by a vector search query is the set of its nearest neighbors $G$, and a cache serves the query with a similar set $X'$.

\textbf{FreshVamana.}  
QVCache manages vectors stored in memory as a graph structure. It starts empty and incrementally populates its graph index by fetching vectors from the backend database upon cache misses. Consequently, the in-memory index must be fully dynamic, supporting both insertions and deletions to enable efficient eviction. To achieve this, QVCache employs the \textit{FreshVamana} algorithm~\cite{freshdiskann}, which is specifically designed for dynamic graph construction.

Unlike traditional static graph-based indexes, FreshVamana can build the index online. That is, it supports search operations concurrently with vector insertions, a property crucial for QVCache. Similar to other graph-based methods, it performs greedy search during query processing. When inserting a new vector, FreshVamana searches the existing graph to identify a set of candidate nodes, then connects the new vector to these candidates. To maintain graph sparsity, if any nodeâ€™s out-degree exceeds a predefined threshold, a pruning procedure called \textit{RobustPrune}~\cite{freshdiskann} removes redundant edges while preserving navigability. FreshVamana also supports dynamic deletions; however, QVCache does not rely on this fine-grained deletion mechanism and instead adopts a coarser-grained eviction strategy through mini-indexes, tailored to its cache-oriented design.
