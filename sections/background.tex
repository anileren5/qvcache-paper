\section{Background} 
This section reviews the foundations of vector search and similarity caching, and summarizes the FreshVamana index~\cite{freshdiskann}, which underpins the design of QVCache.
%In this section, we provide the preliminaries on vector search and the similarity caching problems. Further, we briefly review the FreshVamana index~\cite{freshdiskann}, which serves as the foundation for QVCache.

\textbf{Nearest Neighbor Search.} The \textit{k-nearest neighbor (k-NN)} problem, also referred to as vector search, can be formally defined as follows: Given a set of vectors $P$ in a $d$-dimensional space, i.e., $\forall p \in P, \; p \in \mathbb{R}^d$, and a query vector $q \in \mathbb{R}^d$, the objective is to return a set $X \subseteq P$ of $k$ vectors closest to $q$ according to a distance function $d$. That is, $|X| = k  \land \forall p \in P \setminus X, \; d(q, x_i) \le d(q, p), \; x_i \in X.$ 
The exact solution relies on exhaustive search, which computes distances between $q$ and all vectors in $P$, incurring a time complexity of $O(|P| \cdot d)$.
%The most straightforward solution is \textit{exhaustive search}, which compares the query vector $q$ against all vectors in $P$, resulting in a time complexity of $O(|P|
% \cdot d)$. 
This cost is prohibitive at scale, motivating extensive research on \emph{Approximate Nearest Neighbor (ANN)} search. ANN methods trade exactness for efficiency by reducing the number of distance evaluations~\cite{diskann,HNSWMalkovY16,elpis,nsg,spann} and/or lowering the cost of individual distance computations~\cite{product-quantization}. This trade-off typically manifests as reduced recall.
%To reduce this computational cost, vector search research has largely focused on \textit{Approximate Nearest Neighbor (ANN) search}, which aims to minimize both the number of comparisons~\cite{diskann,HNSWMalkovY16,elpis,nsg,product-quantization,faiss,spann} and the cost of each comparison~\cite{product-quantization} with a trade-off of recall drop.

\textbf{Metrics.} The accuracy of ANN algorithms is commonly evaluated using \textit{k-recall@k}, defined as 
%To evaluate the accuracy of an ANN search method with respect to the ground-truth obtained via exhaustive search, the metric \textit{k-recall@k} is commonly used. It is computed as 
$
\frac{|X' \cap X|}{k},
$ 
where $X'$ is the result set returned by the ANN algorithm, $X$ represents the exact $k$-NN result obtained via exhaustive search, also known as ground-truth. System performance is typically characterized using \emph{latency} and \emph{throughput}, measured in queries per second (QPS).
%neighbors obtained from exhaustive search, and $k$ is the number of neighbors of interest for the query. For performance evaluation, \textit{latency} and \textit{throughput} (queries per second, QPS) are the two standard measures.

\textbf{Similarity Caching.}  
Vector caching builds upon the formal concept of the \textit{similarity caching} problem, where a user request for an object $O$ that is not in the cache may instead be served by a similar object $O'$ from the cache, at the cost of some degradation in user experience~\cite{similarity-caching-theory-algorithms}. The goal of similarity caching is to maximize the cache hit ratio while minimizing this degradation. A query $q$ requesting object $O$ results in a cache hit if there exists a cached object $O'$ retrieved by another query $p$ such that $d(q, p) \le r$, where $d$ is the distance (similarity) metric and $r$ is a similarity threshold~\cite{similarity-caching}. Choosing an appropriate value for $r$ is challenging: if $r=0$, the problem reduces to exact caching with nearly zero hit rate, while a large $r$ leads to poor user experience due to dissimilar results. Chierichetti et al.~\cite{similarity-caching} further show that the problem becomes even harder when $r$ is query-dependent, for which no competitive algorithm exists. Vector caching is exactly such a case, where the object requested by a vector search query is the set of its nearest neighbors $X$, and a cache serves the query with a similar set $X'$.

\textbf{FreshVamana.}  \label{sec:background-freshvamana}
QVCache organizes cached vectors as multiple in-memory graph indexes, which we call \emph{mini-indexes}, and incrementally populates them on cache misses by fetching vectors from the backend store. This setting requires a fully dynamic index that supports online insertions and efficient eviction. QVCache adopts the \emph{FreshVamana} algorithm~\cite{freshdiskann}, which is specifically designed for dynamic graph-based ANN indexing.
%QVCache manages vectors stored in memory as a graph structure. It starts empty and incrementally populates its graph index by fetching vectors from the backend database upon cache misses. Consequently, the in-memory index must be fully dynamic, supporting both insertions and deletions to enable efficient eviction. To achieve this, QVCache employs the \textit{FreshVamana} algorithm~\cite{freshdiskann}, which is specifically designed for dynamic graph construction.

Unlike static graph indexes, FreshVamana supports concurrent search and insertion. Query processing follows a greedy graph traversal, similar to other proximity graph methods. Upon inserting a new vector, the algorithm searches the existing graph to identify candidate neighbors and establishes edges accordingly. %To control graph degree and maintain navigability, FreshVamana applies a pruning procedure, \emph{RobustPrune}~\cite{freshdiskann}, whenever a node exceeds a predefined out-degree bound, removing redundant edges while preserving search quality.
%Unlike traditional static graph-based indexes, FreshVamana can build the index online. That is, it supports search operations concurrently with vector insertions, a property crucial for QVCache. Similar to other graph-based methods, it performs greedy search during query processing. When inserting a new vector, FreshVamana searches the existing graph to identify a set of candidate nodes, then connects the new vector to these candidates. To maintain graph sparsity, if any nodeâ€™s out-degree exceeds a predefined threshold, a pruning procedure called \textit{RobustPrune}~\cite{freshdiskann} removes redundant edges while preserving navigability. FreshVamana also supports dynamic deletions; however, QVCache does not rely on this fine-grained deletion mechanism and instead adopts a coarser-grained eviction strategy through mini-indexes, tailored to its cache-oriented design.

Although FreshVamana supports fine-grained deletions, QVCache does not rely on this mechanism directly. Instead, it employs a coarser eviction policy based on mini-indexes, which better aligns with cache management requirements and reduces deletion overhead.