\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth,trim=0 120 0 0,clip]{figures/perturbation.pdf}
        \caption{Synthesizing queries with semantic (spatial) locality.}
        \label{fig:query-perturbation}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth,trim=0 120 0 0,clip]{figures/workload-generation.pdf}
        \caption{Workload generation with temporal–semantic locality.}
        \label{fig:sliding-window}
    \end{subfigure}
    \caption{Evaluation framework proposed in this paper for benchmarking vector caches, used to evaluate QVCache.}
    \label{fig:evaluation-framework}
    \vspace{-\baselineskip}
\end{figure*}

\section{Evaluation Framework}
%Real-world vector search workloads exhibit skewed access patterns \cite{298625SmartANN, incrementalivfindexmaintenance}, with spatially close queries recurring (i.e., {temporal-semantic locality}), but existing systems are typically evaluated without accounting for this behavior, which is inadequate for assessing vector caches. Standard benchmarks execute each query only once and report aggregate metrics such as average recall and latency, which is sufficient for evaluating standalone ANN systems but insufficient for understanding the cache behavior. 

Real-world vector search workloads exhibit skewed access patterns~\cite{298625SmartANN, incrementalivfindexmaintenance}, with spatially close queries recurring (i.e. \textit{temporal–semantic locality}). However, existing systems are typically evaluated without accounting for this behavior, which is inadequate for assessing vector caches. In standard benchmarks, queries provided in the datasets rarely have overlapping neighbors, and each query is executed only once; benchmarks then report aggregate metrics such as average recall and latency. While this is sufficient for evaluating standalone ANN systems, it is insufficient for understanding cache behavior due to the lack of temporal–semantic locality.

To address this, we propose a workload generation framework that produces query patterns exhibiting temporal-semantic locality at varying degrees. As illustrated in Figure \ref{fig:query-perturbation}, we first partition the queries from the dataset into $N_{\text{split}}$ disjoint subsets to model shifts in the working set of the workload. 
Within each subset (split), we generate perturbed variants for each query to model the temporal-semantic locality. For a query $q$, we sample a random vector $r$ from the data vectors in the dataset and produce  

\begin{equation}
q' = (1-\eta) \cdot q + \eta \cdot r
\label{exp:perturbation-expression}
\end{equation}

\noindent where $\eta$ controls the noise ratio. This interpolation yields queries that are semantically similar, i.e., spatially close, while remaining distinct. % enabling evaluation of vector caches. 
As shown in Figure \ref{fig:overlap-analysis}, the similarity between the base and perturbed queries' neighbor sets decreases sharply with increased noise. At $\eta = 0.01$, roughly 95\% of nearest neighbors overlap, simulating queries that differ in phrasing but share similar intent.


As visualized in Figure \ref{fig:sliding-window}, to generate recurrence of spatially close queries and drifts in the working set, we employ a windowed query pattern \cite{10.14778/2735461.2735465inmemoryperformanceforbigdata}. Each window consists of perturbed versions of $WINDOW\_SIZE$ many base splits. Queries within the window are randomly shuffled and dispatched to the system, repeating $N_{\text{repeat}}$ times. After each repetition, $stride$ out of $WINDOW\_SIZE$ perturbed splits are replaced with new ones. This process continues until the window reaches the last splits, and the cycle can optionally be repeated $N_{\text{round}}$ times with fresh perturbed copies.

The parameter $WINDOW\_SIZE$ controls the working set size (i.e., the number of vectors brought into the cache per window) of the workload. $N_{\text{repeat}}$ measures short-term memory, i.e., the ability to capture cache hits within a short time window, while $N_{\text{round}}$ measures long-term memory across multiple cycles. The ratio $stride/WINDOW\_SIZE$ adjusts how quickly the working set drifts \label{sec:drift-amount} \cite{10.14778/2735461.2735465inmemoryperformanceforbigdata}. Together, these parameters allow us to generate workloads with varying locality and temporal characteristics, enabling comprehensive evaluation of vector caches.
