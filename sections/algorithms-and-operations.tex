\section{Algorithms and Operations}
This section presents the overall architecture of QVCache, the unique challenges it addresses, and the algorithms and operations underlying its core components.

\subsection{Tiered Search}

\begin{algorithm}[htbp]
\caption{\textsc{TieredSearch}}
\label{alg:tiered-search}
\begin{algorithmic}[1]
\State \textbf{Input:} $Q$, $k$
\State \textbf{Output:} Ids of the neighbor set $\text{ID}$, their distances to $Q$, $\text{d}$
\State $(\text{ID}_{\text{cache}}, \text{d}_{\text{cache}}) \gets \textsc{CacheSearch}(Q, k)$
\If{$\textsc{IsHit}(Q, k, \text{d}_{\text{cache}})$}
    \State \Return $(\text{ID}_{\text{cache}}, \text{d}_{\text{cache}})$
\Else
    \State $(\text{ID}_{\text{backend}}, \text{d}_{\text{backend}}) \gets \textsc{BackendSearch}(Q, k)$
    \State \textsc{AsyncCacheFill}$(\text{ID}_{\text{backend}})$
    \State \textsc{AsyncLearnThreshold}$(Q, \text{d}_{\text{backend}}, k)$
    \State \Return $(\text{ID}_{\text{backend}}, \text{d}_{\text{backend}})$
\EndIf
\end{algorithmic}
\end{algorithm}


QVCache is a query-level vector cache, analogous to systems like Redis~\cite{redis2025}, that operates in front of the main vector database (referred to as the backend database). Upon receiving a query, QVCache first attempts to answer it directly from the cache. If it determines that the cached result is sufficiently reliable (\textsc{IsHit} returns \textit{True} in Algorithm~\ref{alg:tiered-search}), the response is served without accessing the backend. Otherwise, the query is forwarded to the backend database for processing. QVCache is \textit{backend-agnostic}, working with any vector database that provides the following interfaces, which most modern systems support:
\begin{itemize}
    \item \texttt{search(Q, k) → (ID, d)}: retrieves the nearest neighbor IDs and distances for a query vector.
    \item \texttt{fetch(ID[]) → Vector[]}: fetches the vectors corresponding to the given IDs.
\end{itemize}

\begin{figure}[t]
  \centering
  \begin{minipage}[t]{0.48\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/first.pdf}% first image
  \end{minipage}
  \hfill
  \begin{minipage}[t]{0.48\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/second.pdf}% second image
  \end{minipage}
  \caption{Initial queries help QVCache learn spatial similarity thresholds (left), and subsequent queries falling into these regions are classified as cache hits or misses (right). Blue dots represent database vectors, green dots queries resulting in cache hits, and red dots queries resulting in cache misses.}
  \label{fig:spatial-thresholds}
\end{figure}

\begin{algorithm}[htbp]
\caption{\textsc{IsHit}}
\label{alg:is-hit}
\begin{algorithmic}[1]
\State \textbf{Input:} $Q$, $k$, $\text{d}_{\text{cache}}$ (sorted in ascending order)
\State \textbf{Output:} True if cache hit, False otherwise
\State $R \gets \textsc{ComputeRegionKey}(Q)$
\If{$\text{d}_{\text{cache}}[k] \le (1 + D) \cdot \theta_k[R]$}
    \State \Return True
\EndIf
\State \Return False
\end{algorithmic}
\end{algorithm}

\subsection{Cache Hit and Miss Decisions}
Deciding if a vector search query can be answered from cache (see \textsc{IsHit}, Algorithm~\ref{alg:is-hit}) is a similarity caching problem~\cite{similarity-caching, similarity-caching-theory-algorithms}. A query is considered a cache hit if the distance of the query vector to the furthest vector in the candidate neighbor set ($d_{\text{cache}}[k]$) is less than or equal to a \textit{similarity threshold}, $\theta$. Determining the optimal threshold to maximize hit ratios while maintaining the recall of the backend database is challenging.

\vspace{1ex}
 \textbf{Challenge 1: No universal threshold across datasets.} Different datasets may require substantially different distance thresholds, making manual tuning impractical.  

 \textit{Solution: Adaptive threshold learning.} QVCache continuously adapts its thresholds while processing queries (Algorithm~\ref{alg:learn-threshold}), allowing it to adjust dynamically to varying datasets and query patterns.

\vspace{1ex}
 \textbf{Challenge 2: Spatial heterogeneity.} Vectors in a database are distributed non-uniformly across the high-dimensional space (see Figure~\ref{fig:spatial-thresholds}). Some regions are dense and highly clustered, while others are sparse, and certain regions contain more vectors than others. Consequently, a single global similarity threshold may perform well for some queries but poorly for others, even though the dataset is the same.

 \textit{Solution: Spatial thresholds.} It partitions the high-dimensional space into sub-regions (sub-spaces) and assigns a separate similarity threshold to each. These thresholds are learned independently, and for a given query, QVCache uses the threshold corresponding to the sub-region (sub-space) onto which the query vector falls to make cache hit decisions.


\vspace{1ex}
 \textbf{Challenge 3: Thresholds Vary with k.} As the parameter $k$ in a vector search query increases, the system generally requires a higher threshold. However, the threshold for a larger $k$ (e.g., $k=10$) cannot be inferred from that of a smaller $k$ (e.g., $k=1$), as there is no deterministic relationship; it largely depends on the heterogeneity of the data distribution.  

 \textit{Solution: Per-$k$ Thresholds.} QVCache maintains an independent threshold for each observed $k$ and learns them separately.

\vspace{1ex}
To implement these solutions, QVCache maintains a 2-D array of thresholds. As shown in Algorithm~\ref{alg:is-hit}, the first dimension is resolved by finding the region onto which the query falls, while the second dimension corresponds to the parameter $k$. When evaluating whether a query is a cache hit, the system does not directly compare the distance of the furthest vector in the candidate set, $\text{d}_{\text{cache}}[k]$, with the threshold. Instead, it applies a multiplicative adjustment using the \textit{deviation factor}, $D$. This factor serves as a tunable knob that balances cache hit ratio and recall: increasing $D$ raises the hit ratio but may lead to reduced recall. Such a knob provides flexibility for users to adapt QVCache to systems with different accuracy and performance requirements beyond the learned thresholds.


\begin{algorithm}[htbp]
\caption{\textsc{LearnThreshold}}
\label{alg:learn-threshold}
\begin{algorithmic}[1]
\State \textbf{Input:} $Q$, $k$, $\text{d}_{\text{backend}}$ (sorted in ascending order)
\State $R \gets \textsc{ComputeRegionKey}(Q)$
\State $\theta_k[R] \gets (1 - \alpha) \cdot \theta_k[R] + \alpha \cdot \text{d}_{\text{backend}}[k]$
\end{algorithmic}
\end{algorithm}

  
\subsection{Learning Thresholds}
In  Algorithm~\ref{alg:learn-threshold}, QVCache uses the distance of the furthest vector in the candidate set generated by itself, $\text{d}_{\text{cache}}[k]$. On the other hand, it uses the distance of the furthest vector returned by the backend database, $\text{d}_{\text{backend}}[k]$ to learn the spatial thresholds,  $\theta_k[R]$ in  Algorithm~\ref{alg:is-hit},. Ideally, $\text{d}_{\text{cache}}[k]$ converges to $\text{d}_{\text{backend}}[k]$ for a cache hit. Notably, QVCache and the backend database must use the same distance function (metric) to ensure these quantities are comparable and that hit evaluation remains consistent

The threshold update rule in QVCache is inspired by the Adam optimizer~\cite{adamoptimizer}, which updates momentum using gradients during neural network training. Similarly, QVCache updates thresholds using feedback from backend query results. The update employs an \textit{adaptivity rate} $\alpha$, which determines how quickly QVCache adapts to changes in the query distribution. The parameter $\alpha$ ranges between 0 and 1, with values around 0.9 performing well in our experiments.

The first term in the update equation preserves memory of past query behavior, while the second term enables adaptation to evolving query distributions. A higher adaptivity rate allows QVCache to adjust more quickly to shifts in query distributions but also causes it to forget past query patterns faster. This balance enables QVCache to remain both stable and responsive under dynamic workloads.

For each query resulting in a cache miss, QVCache populates the cache by fetching the corresponding vectors from the backend database and inserting them into the appropriate mini-indexes, while also updating the thresholds using Algorithm~\ref{alg:learn-threshold}. To avoid using stale index data that could degrade recall, threshold updates are performed only after the cache has been populated. Fetching vectors from the backend can be costly depending on the deployment strategy and the backend database's access path to vectors. QVCache avoids blocking the critical query path, minimizing latency by executing both the cache population and threshold update asynchronously through a pool of background threads, as described in Algorithm~\ref{alg:tiered-search}.

Due to the asynchronous execution of these tasks, if QVCache receives a similar or identical query during the interval between a cache miss and the completion of the update, it may result in a cache miss. This occurs because the thresholds used during this period are still stale, even though the query would have been a cache hit after the update is applied.

\subsection{Scalable Spatial Thresholding in High Dimensions}
QVCache partitions the high-dimensional vector space into sub-spaces by dividing each dimension into ${\text{n}}_{\text{buckets}}$ buckets. Upon receiving a query, it identifies the bucket corresponding to each dimension (\textsc{ComputeRegionKey}(Q)) to determine the appropriate spatial threshold.

Many datasets contain vectors with over 100 dimensions. For instance, a dataset uses $d = 128$ dimensional vectors, with ${\text{n}}_{\text{buckets}} = 16$ and 4-byte floating point numbers to store thresholds. Storing thresholds for all possible sub-space combinations would require $128^{16} \cdot 4$ bytes, which is infeasible.

\textbf{Dimensionality reduction.} Not all dimensions of a vector contribute equally to cache-hit decisions. Therefore, QVCache projects incoming query vectors onto a lower-dimensional space via Principal Component Analysis (PCA) \cite{principalcomponentanalysis} and uses this reduced space for both threshold assignment and learning. QVCache performs a lightweight offline training step to compute the transformation matrix and determine the boundaries of each reduced dimension for bucket partitioning. QVCache employs a straightforward partitioning scheme, dividing each dimension of the reduced-dimensional space into equal-sized buckets using hyperplanes parallel to the axes. However, more advanced partitioning strategies that account for dataset-specific characteristics could be explored as future work. This process does not require the entire dataset; according to our experiments, random sampling of as little as 0.1\%–0.01\% of the dataset is sufficient. The \textsc{ComputeRegionKey} function then applies this transformation matrix to project each query vector into the reduced space.

For instance, if ${\text{d}}_{\text{reduced}} = 8$, the memory requirement becomes $8^{16} \cdot 4$ bytes. Although this technique significantly reduces the memory footprint, it still exceeds the practical constraints under which QVCache is designed to operate.

\textbf{Lazy initialization.} Similar to how database vectors tend to cluster, queries also exhibit spatial locality, meaning that not every region of the vector space will receive queries. Consequently, QVCache does not allocate memory for thresholds in regions that have not yet been queried; a missing key implicitly represents a region which has not been hit yet. Memory is allocated only when the first query falls into a new region and the threshold is initialized to the first distance returned by the backend . Our experiments show that, for most datasets, at most 100,000 regions become active, consuming approximately 400~KB of memory. If the number of active regions exceeds a user-defined limit, QVCache can evict thresholds (by resetting them to zero and freeing memory) using an eviction policy such as LRU, and relearn them later as needed. This lazy initialization, combined with dimensionality reduction, allows QVCache to maintain an exceptionally low memory footprint.


\subsection{Mini-indexes}
QVCache organizes its in-memory vectors using the FreshVamana graph structure \cite{freshdiskann}. Instead of maintaining a single monolithic mini-index, it manages multiple mini-indexes concurrently. This design both narrows the search space during lookups and enables QVCache to treat each mini-index as an independent unit for cache eviction.

\textbf{Insertion.}
QVCache maintains metadata to track access patterns across its mini-indexes, ranking them from hottest to coldest based on the chosen eviction policy. Under the default LRU policy, the hottest mini-index corresponds to the most recently used one. Upon a cache miss, the system attempts to insert new vectors into the hottest mini-index during the \textsc{CacheFill} operation. If it is full, QVCache looks for a mini-index with available space; if none are available, it evicts one according to the policy before inserting. Each insertion updates the metadata, marking the target mini-index as the hottest. For example, in Figure~\ref{fig:architecture}, the system inserts into Mini-index~2, identified as the hottest according to the eviction policy.

\textbf{Search.} Unlike traditional caches that use hash tables and provide $O(1)$ lookups regardless of cache size, QVCache relies on the FreshVamana~\cite{freshdiskann} graph-based index, whose search converges in logarithmic time. If not carefully managed, larger cache sizes (${\text{n}}_{\text{mini-index}} \cdot {\text{c}}_{\text{mini-index}}$) can increase query latency. To maintain bounded and predictable latency, QVCache leverages its mini-index structure and employs four search strategies that balance search quality and efficiency.

\begin{itemize}
    \item \textbf{\texttt{SEQUENTIAL:}} This strategy performs searches across all mini-indexes one by one and merges (re-ranks) the results to form the final candidate set. However, its latency increases linearly with ${\text{n}}_{\text{mini-index}}$.  

    \item \textbf{\texttt{EAGER:}} Since QVCache inserts new vectors from ${\text{N}}_{\text{backend}}$ into the hottest mini-index, scanning the hottest ones is often sufficient to generate a complete candidate set for a cache hit. This approach traverses mini-indexes in the order defined by the eviction metadata, starting from the hottest, and stops as soon as \textsc{IsHit} returns \texttt{True}. When each mini-index is sufficiently large (i.e., ${\text{c}}_{\text{mini-index}}$ exceeds the working set~\cite{working-set} of the workload), this strategy achieves a confident candidate set from the first mini-index, effectively bounding latency to the cost of a single mini-index search (proportional to $\log c_{\text{mini-index}}$), regardless of ${\text{n}}_{\text{mini-index}}$.  

    \item \textbf{\texttt{ADAPTIVE:}} The eager-sequential strategy can experience temporary recall degradation when the query distribution shifts sharply. In such cases, recently inserted vectors may be distributed across multiple mini-indexes, preventing the hottest index alone from producing accurate results. To handle this, QVCache uses an adaptive approach that observes runtime indicators like the hit ratio of recent queries (for instance, across the past 1 000 requests). If the hit ratio drops below a threshold (e.g., 90\%), indicating a distribution shift, the system temporarily switches to the \texttt{SEQUENTIAL} strategy. Otherwise, it continues using the \texttt{EAGER} approach. This adaptive strategy achieves the best balance between performance stability and efficiency in most cases.
    
    \item \textbf{\texttt{PARALLEL:}} Searching all mini-indexes in parallel may seem ideal, but it is often constrained by hardware limitations. QVCache already processes each incoming query on a separate thread to maximize throughput. Executing searches in parallel across all mini-indexes would require ${\text{t}}_{\text{processing}} \cdot {\text{n}}_{\text{mini-index}}$ threads, which scales poorly and degrades overall performance. Nonetheless, this strategy can be effective when minimizing latency is more critical than maximizing throughput, when ${\text{n}}_{\text{mini-index}}$ is small, or when the system has abundant multithreading resources.

\end{itemize}

    For all strategies, mini-indexes that contribute to the candidate set during a cache hit are promoted to a hotter state according to the eviction policy metadata.

     In most cases, the \texttt{ADAPTIVE} strategy offers the best balance, maintaining high recall while keeping latency bounded in a best-effort manner. However, other strategies may be preferable depending on system requirements, available hardware resources and dataset properties.

\vspace{1ex}

\textbf{Eviction.}
FreshVamana handles deletions in two stages. When a node is marked for deletion, it is first flagged as inactive and excluded from subsequent searches, but its memory remains allocated. Periodically, a background \textit{consolidation} process reclaims memory by removing all flagged nodes and reconnecting the surrounding graph. We observed that this lazy deletion strategy introduces two major drawbacks: (1) the consolidation step requires multi-threaded execution, adding significant overhead ~\cite{turbocharging-vector-databases-ssds}  and reducing throughput for workloads with frequently changing working sets ~\cite{working-set}, and (2) infrequent consolidation can cause memory bloat due to accumulated deleted nodes, which is problematic in memory-constrained environments where QVCache operates.

Mini-indexes are the unit of eviction in QVCache. This enables to avoid costly consolidation operation in FreshVamana \cite{freshdiskann} with the cost of coarser-grained information loss while evicting depending the on the capacity of mini-indexes. When all the mini-indexes get full, it evicts one of them accroding to eviction policy, e.g. Mini-index 3 in Figure~\ref{fig:architecture}, and upgraded to the hottest index for the future insertions to be used. 

As discussed in Section 6.4, the capacity of each mini-index plays a critical role in performance. If a mini-index is too small, it triggers frequent evictions and fails to exploit the logarithmic convergence properties of FreshVamana~\cite{freshdiskann}. Conversely, overly large mini-indexes increase both query latency and eviction cost. Ideally, the capacity of each mini-index should approximately match the \textit{working set} size~\cite{working-set}, representing the subset of vectors that are fetched within a reasonably short time window. When allocating additional memory to QVCache, the overall cache size should be scaled by increasing ${\text{n}}_{\text{mini-index}}$ while keeping ${\text{c}}_{\text{mini-index}}$ constant (assuming the working set size remains constant), thereby maintaining stable and efficient latency characteristics.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{plots/noise_ratio_analysis/neighbor_overlap_analysis.pdf}
    \caption{\textbf{Neighbor overlap under perturbation (GIST, $k=10$).} The intersection between the neighbor sets of the base and perturbed queries decays sharply, approaching near-zero at a noise ratio of 0.5.}
    \label{fig:overlap-analysis}
\end{figure}


\begin{figure*}[h]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \input{figures/query_perturbation}
        \caption{Synthesizing Queries with Semantic (Spatial) Locality}
        \label{fig:query-perturbation}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \resizebox{0.8\textwidth}{!}{
            \input{figures/sliding_window_experiment}
        }
        \caption{Workload Generation with temporal-semantic Locality}
        \label{fig:sliding-window}
    \end{subfigure}
    \caption{Evaluation framework proposed in this paper for benchmarking vector caches, used to evaluate QVCache.}
    \label{fig:evaluation-framework}
\end{figure*}